{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab449e6-798e-415a-aa1f-8fada60c96e4",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9d69e-2c9e-4ce6-8b02-4b5c39e3e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "from seqgen.model import seq2seq_lstm\n",
    "from seqgen.vocabulary import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc1b85-450e-4c21-8d75-ec0b4f6783d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e572a-4482-4646-8836-53dc606c74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target_seqs = g.generate_synthetic_training_data(100, max_length=25, swap_times=0, device=device)\n",
    "input_seqs = torch.Tensor(features[:, :, 0]).to(torch.int64)\n",
    "coordinates = torch.Tensor(features[:, :, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bed66-c0e9-4374-8f8c-349effb1bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=2\n",
    "embedding_dim = 100\n",
    "hidden_size=100\n",
    "batch_size=100\n",
    "max_length=25\n",
    "bidirectional=True\n",
    "\n",
    "load_from_checkpoint = True\n",
    "checkpoint_file = \"model_2022-12-25_11-55-53.pt\"\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "encoder = seq2seq_lstm.EncoderRNN(vocab_size=len(vocab_in), embedding_dim=embedding_dim, num_layers=num_layers, hidden_size=hidden_size, bidirectional=bidirectional).to(features.device)\n",
    "decoder = seq2seq_lstm.DecoderRNN(embedding_dim=embedding_dim, num_layers=num_layers, hidden_size=hidden_size, vocab_size=len(vocab_out), bidirectional=bidirectional).to(features.device)\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    encoder.load_state_dict(checkpoint['encoder_model_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a0d93-b722-4d78-96ff-c061563bbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    predictions = torch.zeros(target_seqs.shape).to(torch.int64).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Initialize the encoder hidden state and cell state with zeros\n",
    "        hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "        cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "\n",
    "        # Iterate over the sequence words and run every word through the encoder\n",
    "        for i in range(input_seqs.shape[1]):\n",
    "            output, (hn, cn) = encoder(\n",
    "                input_seqs[:, i].unsqueeze(dim=1),\n",
    "                coordinates[:, i],\n",
    "                (hn, cn)\n",
    "            )\n",
    "\n",
    "        # Predict tokens of the target sequence by running the hidden state through\n",
    "        # the decoder\n",
    "        for i in range(0, target_seqs.size(1)):\n",
    "            output, (hn, cn) = decoder(\n",
    "                target_seqs[:, i].unsqueeze(dim=1),\n",
    "                coordinates[:, i],\n",
    "                (hn, cn)\n",
    "            )\n",
    "            # Select the indices of the most likely tokens\n",
    "            predictions[:, i] = torch.argmax(output, dim=2).squeeze()\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4b6a5-d58b-4d25-b1b8-46586e5bcf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0) - 1)\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i][1:].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i][1:].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b650e-8615-4374-bcd4-9ca071679247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
