{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import rnn\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer, embedding\n",
    "from seqgen.datasets.sequences import *\n",
    "from seqgen.datasets.realdata import RealSequencesDataset\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccbe91c-6286-4398-ad71-ee251ae1af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_dataset=True\n",
    "lr=1e-2\n",
    "num_layers=3\n",
    "embedding_dim=256\n",
    "batch_size=128\n",
    "max_length=50\n",
    "heads=8\n",
    "dropout=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "if use_real_dataset:\n",
    "    dataset = RealSequencesDataset(filename=\"data/train/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device)\n",
    "else:\n",
    "    dataset = SyntheticSequenceDataset(vocab_in, vocab_out, max_length, batch_size, continue_prob=0.95, additional_eos=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 51]), torch.Size([128, 51, 4]), torch.Size([128, 51]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4f2ee2-b6ee-4b52-80c1-9a0f76d147ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 59, 41,  7, 14, 36, 10, 69,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "       device='cuda:0')\n",
      "tensor([  0,  39, 154,  39,   6,  41,  16, 153,  74,  50,  94,  41,   1,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2], device='cuda:0')\n",
      "tensor([ 39, 154,  39,   6,  41,  16, 153,  74,  50,  94,  41,   1,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(input_seqs[0, :-1])\n",
    "print(target_seqs[0, :-1])\n",
    "print(target_seqs[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c23a55-7c29-4a35-b0c4-09dd2a92d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def permutate_tokens(input_seq):\n",
    "#    # Get the first index where tensor has an SOS or EOS token\n",
    "#    sos_idx = list(input_seq).index(0)\n",
    "#    eos_idx = list(input_seq).index(1)\n",
    "#    # permutate all elements that are not SOS or EOS\n",
    "#    idx_permuted = torch.cat([torch.arange(0, sos_idx+1), (torch.randperm(eos_idx - sos_idx - 1) + sos_idx+1), torch.arange(eos_idx, max_length+1)])\n",
    "#    return idx_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5e0242-7e39-4644-abd3-aa5b5c87597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 180, tensor(104, device='cuda:0'), tensor(176, device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_checkpoint = True\n",
    "checkpoint_file = \"transformer_temp2.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.Transformer(\n",
    "    encoder_embedding_type=embedding.EmbeddingType.COORDS_DIRECT,\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=2,\n",
    "    trg_pad_idx=2,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss(ignore_index=2)\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e27831-a686-4ab8-aa8e-0588faf059c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the feature sequences through the model\n",
    "output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 180]),\n",
       " torch.Size([128, 50, 1]),\n",
       " torch.Size([128, 50, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted classes of the model\n",
    "topv, topi = output.topk(1, dim=2)\n",
    "output.shape, topi.shape, topv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.511982116699219"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0.0\n",
    "for i in range(max_length):\n",
    "    _loss = criterion(output[:, i, :], target_seqs[:, i])\n",
    "    if not _loss.isnan():\n",
    "        loss += _loss\n",
    "loss.item() / max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457a9e17-56cd-400a-bd1b-2dff0415f081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 180, tensor(104, device='cuda:0'), tensor(176, device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 0.26096592697442744 LR 0.01 ACCURACY 0.08459791373461485\n",
      "LOSS after epoch 10 0.31306928746840534 LR 0.01 ACCURACY 0.7969392746686935\n",
      "LOSS after epoch 20 0.31270739611457377 LR 0.01 ACCURACY 0.8240177699364721\n",
      "LOSS after epoch 30 0.23830189424402573 LR 0.01 ACCURACY 0.8454198881052435\n",
      "LOSS after epoch 40 0.29472167819154027 LR 0.01 ACCURACY 0.8218481161631643\n",
      "LOSS after epoch 50 0.3146538453943589 LR 0.01 ACCURACY 0.7973871790803969\n",
      "LOSS after epoch 60 0.31584810743144914 LR 0.01 ACCURACY 0.8385578919202089\n",
      "LOSS after epoch 70 0.37378711326449526 LR 0.01 ACCURACY 0.7910651070997119\n",
      "LOSS after epoch 80 0.3250284007951325 LR 0.01 ACCURACY 0.8136963043361902\n",
      "LOSS after epoch 90 0.25999998578838274 LR 0.01 ACCURACY 0.7931235982105136\n",
      "LOSS after epoch 100 0.5397139904545802 LR 0.01 ACCURACY 0.8247704431414604\n",
      "LOSS after epoch 110 0.3331750981947955 LR 0.01 ACCURACY 0.8432143396697939\n",
      "LOSS after epoch 120 0.3552146986419079 LR 0.01 ACCURACY 0.7967556213960052\n",
      "LOSS after epoch 130 0.32756618424957873 LR 0.01 ACCURACY 0.7920181893743574\n",
      "LOSS after epoch 140 0.23037809484145222 LR 0.01 ACCURACY 0.8288461592048406\n",
      "LOSS after epoch 150 0.2578786214192708 LR 0.01 ACCURACY 0.8430927014909685\n",
      "LOSS after epoch 160 0.22559278151568243 LR 0.01 ACCURACY 0.8061852642334998\n",
      "LOSS after epoch 170 0.255343942081227 LR 0.01 ACCURACY 0.8126021541655064\n",
      "LOSS after epoch 180 0.2550661423627068 LR 0.01 ACCURACY 0.8434317491017282\n",
      "LOSS after epoch 190 0.23126839656455844 LR 0.01 ACCURACY 0.8369340558536351\n",
      "LOSS after epoch 200 0.3684964273490158 LR 0.01 ACCURACY 0.801007519569248\n",
      "LOSS after epoch 210 0.21702605602787992 LR 0.01 ACCURACY 0.8727872218005359\n",
      "LOSS after epoch 220 0.1445015645494648 LR 0.01 ACCURACY 0.8174795298837125\n",
      "LOSS after epoch 230 0.2789926902920592 LR 0.01 ACCURACY 0.8157917944714427\n",
      "LOSS after epoch 240 0.23568087933110257 LR 0.01 ACCURACY 0.8280974404886365\n",
      "LOSS after epoch 250 0.24967722799263747 LR 0.01 ACCURACY 0.8241965330205858\n",
      "LOSS after epoch 260 0.14595818987079695 LR 0.01 ACCURACY 0.8279065756127238\n",
      "LOSS after epoch 270 0.205108175090715 LR 0.01 ACCURACY 0.8430528597906232\n",
      "LOSS after epoch 280 0.20232755997601679 LR 0.01 ACCURACY 0.8200586418621242\n",
      "LOSS after epoch 290 0.2074580473058364 LR 0.01 ACCURACY 0.8576376423239708\n",
      "LOSS after epoch 300 0.27478646297080844 LR 0.01 ACCURACY 0.8534166415221989\n",
      "LOSS after epoch 310 0.21559932185154335 LR 0.01 ACCURACY 0.8544018926098943\n",
      "LOSS after epoch 320 0.3132755990121879 LR 0.01 ACCURACY 0.8603238116949796\n",
      "LOSS after epoch 330 0.23432140724331724 LR 0.01 ACCURACY 0.8288061757571995\n",
      "LOSS after epoch 340 0.17486809749229282 LR 0.01 ACCURACY 0.837784787081182\n",
      "LOSS after epoch 350 0.22144027784758924 LR 0.01 ACCURACY 0.8694896610453725\n",
      "LOSS after epoch 360 0.11137980105830174 LR 0.01 ACCURACY 0.8361803449690342\n",
      "LOSS after epoch 370 0.26199976603190106 LR 0.01 ACCURACY 0.8522576933726669\n",
      "LOSS after epoch 380 0.19219806147556678 LR 0.01 ACCURACY 0.8142532238736748\n",
      "LOSS after epoch 390 0.24822530559464998 LR 0.01 ACCURACY 0.8601681685075164\n",
      "LOSS after epoch 400 0.21206178852156096 LR 0.01 ACCURACY 0.8363765643909573\n",
      "LOSS after epoch 410 0.20554003996007583 LR 0.01 ACCURACY 0.86770413024351\n",
      "LOSS after epoch 420 0.21852741989434935 LR 0.01 ACCURACY 0.8358714316040278\n",
      "LOSS after epoch 430 0.16047113081988165 LR 0.01 ACCURACY 0.8492512476630509\n",
      "LOSS after epoch 440 0.15800141353233188 LR 0.01 ACCURACY 0.8499548084102571\n",
      "LOSS after epoch 450 0.1616046381931679 LR 0.01 ACCURACY 0.8535852048546075\n",
      "LOSS after epoch 460 0.302860746196672 LR 0.01 ACCURACY 0.8363716148771345\n",
      "LOSS after epoch 470 0.1890569013707778 LR 0.01 ACCURACY 0.822602741792798\n",
      "LOSS after epoch 480 0.2288662218580059 LR 0.01 ACCURACY 0.8473301073536277\n",
      "LOSS after epoch 490 0.17731608596502565 LR 0.01 ACCURACY 0.8375382235273718\n",
      "LOSS after epoch 500 0.1952955395567651 LR 0.01 ACCURACY 0.8613885621540248\n",
      "LOSS after epoch 510 0.19292481740315756 LR 0.01 ACCURACY 0.8405032327398658\n",
      "LOSS after epoch 520 0.24836166232239967 LR 0.01 ACCURACY 0.8402981820516289\n",
      "LOSS after epoch 530 0.17021304485844632 LR 0.01 ACCURACY 0.8424502858892083\n",
      "LOSS after epoch 540 0.17051412544998468 LR 0.01 ACCURACY 0.870424373075366\n",
      "LOSS after epoch 550 0.1986542309031767 LR 0.01 ACCURACY 0.8429050136357545\n",
      "LOSS after epoch 560 0.20946844886330998 LR 0.01 ACCURACY 0.8625734725967049\n",
      "LOSS after epoch 570 0.20021393719841452 LR 0.01 ACCURACY 0.8378656821325421\n",
      "LOSS after epoch 580 0.23067470625335096 LR 0.01 ACCURACY 0.8640852438285946\n",
      "LOSS after epoch 590 0.18456230911554075 LR 0.01 ACCURACY 0.8232873980887234\n",
      "LOSS after epoch 600 0.162658036923876 LR 0.01 ACCURACY 0.8439171336591244\n",
      "LOSS after epoch 610 0.13390063304527133 LR 0.01 ACCURACY 0.851839776430279\n",
      "LOSS after epoch 620 0.2036587771247415 LR 0.01 ACCURACY 0.8436919886618852\n",
      "LOSS after epoch 630 0.1456786978478525 LR 0.01 ACCURACY 0.8345352288335561\n",
      "LOSS after epoch 640 0.20481391981536268 LR 0.01 ACCURACY 0.8523024763911963\n",
      "LOSS after epoch 650 0.2018748264686734 LR 0.01 ACCURACY 0.8718141032382846\n",
      "LOSS after epoch 660 0.16300498738008387 LR 0.01 ACCURACY 0.8801145384088158\n",
      "LOSS after epoch 670 0.1255494379529766 LR 0.01 ACCURACY 0.8370867386460304\n",
      "LOSS after epoch 680 0.3075828178256166 LR 0.01 ACCURACY 0.8423713068477809\n",
      "LOSS after epoch 690 0.17517882702397367 LR 0.01 ACCURACY 0.854296300560236\n",
      "LOSS after epoch 700 0.2057949514950023 LR 0.01 ACCURACY 0.8462914924137295\n",
      "LOSS after epoch 710 0.17119777903837316 LR 0.01 ACCURACY 0.8411899745464325\n",
      "LOSS after epoch 720 0.13897277794632257 LR 0.01 ACCURACY 0.8188833240419626\n",
      "LOSS after epoch 730 0.1296677121929094 LR 0.01 ACCURACY 0.8651768457144499\n",
      "LOSS after epoch 740 0.14316716848635205 LR 0.01 ACCURACY 0.8886094190180301\n",
      "LOSS after epoch 750 0.1304344382940554 LR 0.01 ACCURACY 0.8677649985998869\n",
      "LOSS after epoch 760 0.16791347428864123 LR 0.01 ACCURACY 0.8627611938863993\n",
      "LOSS after epoch 770 0.11686468124389648 LR 0.01 ACCURACY 0.8542113657109439\n",
      "LOSS after epoch 780 0.12610309264239142 LR 0.01 ACCURACY 0.8864532861858606\n",
      "LOSS after epoch 790 0.09893083572387695 LR 0.01 ACCURACY 0.8633704174309969\n",
      "LOSS after epoch 800 0.15886888317033357 LR 0.01 ACCURACY 0.8780263064429163\n",
      "LOSS after epoch 810 0.17931431415034274 LR 0.01 ACCURACY 0.9063132267445326\n",
      "LOSS after epoch 820 0.1490947218502269 LR 0.01 ACCURACY 0.8543864930048585\n",
      "LOSS after epoch 830 0.1128690289516075 LR 0.01 ACCURACY 0.8611068669706583\n",
      "LOSS after epoch 840 0.11876911275527056 LR 0.01 ACCURACY 0.8779248120263219\n",
      "LOSS after epoch 850 0.13268165027394013 LR 0.01 ACCURACY 0.8523760238662362\n",
      "LOSS after epoch 860 0.15359918743956322 LR 0.01 ACCURACY 0.8507301546633244\n",
      "LOSS after epoch 870 0.10462171891156365 LR 0.01 ACCURACY 0.8897327791899443\n",
      "LOSS after epoch 880 0.20121080735150507 LR 0.01 ACCURACY 0.884007666260004\n",
      "LOSS after epoch 890 0.1888428482354856 LR 0.01 ACCURACY 0.8785181363113225\n",
      "LOSS after epoch 900 0.13811980041803099 LR 0.01 ACCURACY 0.8805598918348551\n",
      "LOSS after epoch 910 0.14277137494554706 LR 0.01 ACCURACY 0.8716949868947268\n",
      "LOSS after epoch 920 0.1386236863977769 LR 0.01 ACCURACY 0.8656233254820108\n",
      "LOSS after epoch 930 0.12009823556039848 LR 0.01 ACCURACY 0.8518879186362028\n",
      "LOSS after epoch 940 0.15119510538437786 LR 0.01 ACCURACY 0.8344909597188235\n",
      "LOSS after epoch 950 0.12214141733506147 LR 0.01 ACCURACY 0.8664069355465471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOSS after epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m (target_seqs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCURACY\u001b[39m\u001b[38;5;124m\"\u001b[39m, _accuracy)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Compute gradient\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Update weights of encoder and decoder\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(10000):    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    \n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    #####################\n",
    "    #    TRANSFORMER    #\n",
    "    #####################\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])\n",
    "    loss = criterion(output[:, 0, :], target_seqs[:, 1])\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(1, max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        _loss = criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        if not _loss.isnan():\n",
    "            loss += _loss\n",
    "            mask = target_seqs[:, i+1] != 2\n",
    "            accuracy += float((topi.squeeze()[mask] == target_seqs[mask, i+1]).sum() / (target_seqs[mask].size(0)*(target_seqs[mask].size(1)-2)))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print_every = 10\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item() / (target_seqs.size(1)), \"LR\", lr, \"ACCURACY\", _accuracy)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.to(device), target_seqs.to(device), coordinates.to(device))\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b4224ca-ab02-437b-a0ea-5704b1c01daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict_sequentially(input_seqs, coordinates)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INPUT ['-', 'x', '3', '2', '=', '\\\\sqrt', '1', '6', '<end>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "MODEL OUTPUT ['\\\\frac', '{', '{', '3', '}', '{', '2', '}', '}', '}', '{', 'x', '}', '=', '\\\\sqrt', '{', '1', '}', '}', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
      "TARGET OUTPUT ['\\\\frac', '{', '{', '3', '^', '{', '2', '}', '}', '}', '{', 'x', '}', '=', '\\\\sqrt', '{', '1', '6', '}', '<end>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i, 1:].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i, :-1].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i, 1:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deeae19b-77d4-4715-8068-9822af23009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT \\frac{{3}{2}}}{x}=\\sqrt{1}}\n"
     ]
    }
   ],
   "source": [
    "prediction = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "prediction = list(filter(lambda x: x != '<end>', prediction))\n",
    "prediction = \"\".join(prediction)\n",
    "print(\"MODEL OUTPUT\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4141cd30-1b5f-4a10-b844-08b2cbb28576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 39,  41,  39,  41,  39,  47,  41,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   0],\n",
       "        [ 50,   3,  18,  18,  39,  16,  49,  41,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   0],\n",
       "        [ 39,  16, 151,  41,  39,  39,  41,  39,  41,  39,  41,  39,  41,  68,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sequentially(input_seqs[0:3], coordinates[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e1244-c9b2-4f1e-8e7c-58ad12ccd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0:3, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6130ca-cb78-49d1-b167-b6d0817afbbc",
   "metadata": {},
   "source": [
    "## Prediction for permutated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472c7a7-3c27-46d4-ba18-e4cbf9d52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutated_batch(input_seq, coordinates):\n",
    "    seqs = torch.zeros((5, input_seq.size(0))).to(torch.int64)\n",
    "    coords = torch.zeros((5, coordinates.size(0), coordinates.size(1)))\n",
    "    for i in range(5):\n",
    "        idx_permutated = permutate_tokens(input_seq)\n",
    "        seqs[i, :] = input_seq[idx_permutated]\n",
    "        coords[i, :] = coordinates[idx_permutated]\n",
    "    return seqs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272c96c-9ac8-4ea7-9f84-03c28c81db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_permutated, coords_permutated = generate_permutated_batch(input_seqs[0], coordinates[0])\n",
    "input_permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571029b-a0e2-4574-a70e-f02ca965611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequentially(input_permutated, coords_permutated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5daf2-f175-4e54-bdb0-2f9c1844b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983b254-e462-48ce-bc7e-94c2fba39a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
