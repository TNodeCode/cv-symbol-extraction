{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import rnn\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer, embedding\n",
    "from seqgen.datasets.sequences import *\n",
    "from seqgen.datasets.realdata import RealSequencesDataset\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbe91c-6286-4398-ad71-ee251ae1af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_dataset=False\n",
    "lr=1e-2\n",
    "num_layers=3\n",
    "embedding_dim=128\n",
    "batch_size=256\n",
    "max_length=50\n",
    "heads=8\n",
    "dropout=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\", vocab_file=\"vocab_in.pkl\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\", vocab_file=\"vocab_out.pkl\")\n",
    "\n",
    "if use_real_dataset:\n",
    "    dataset = RealSequencesDataset(filename=\"data/train/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device)\n",
    "else:\n",
    "    dataset = SyntheticSequenceDataset(vocab_in, vocab_out, max_length, batch_size, continue_prob=0.95, additional_eos=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f2ee2-b6ee-4b52-80c1-9a0f76d147ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_seqs[0, :-1])\n",
    "print(target_seqs[0, :-1])\n",
    "print(target_seqs[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c23a55-7c29-4a35-b0c4-09dd2a92d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_tokens(input_seq):\n",
    "    # Get the first index where tensor has an SOS or EOS token\n",
    "    sos_idx = list(input_seq).index(0)\n",
    "    eos_idx = list(input_seq).index(1)\n",
    "    # permutate all elements that are not SOS or EOS\n",
    "    idx_permuted = torch.cat([torch.arange(0, sos_idx+1), (torch.randperm(eos_idx - sos_idx - 1) + sos_idx+1), torch.arange(eos_idx, max_length+1)])\n",
    "    return idx_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e0242-7e39-4644-abd3-aa5b5c87597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_checkpoint = False\n",
    "checkpoint_file = \"transformer_temp2.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.PyTorchTransformerDecoder(\n",
    "    encoder_embedding_type=embedding.EmbeddingType.COORDS_DIRECT,\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=2,\n",
    "    trg_pad_idx=2,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss(ignore_index=2)\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e27831-a686-4ab8-aa8e-0588faf059c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the feature sequences through the model\n",
    "output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes of the model\n",
    "topv, topi = output.topk(1, dim=2)\n",
    "output.shape, topi.shape, topv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.0\n",
    "for i in range(max_length):\n",
    "    _loss = criterion(output[:, i, :], target_seqs[:, i])\n",
    "    if not _loss.isnan():\n",
    "        loss += _loss\n",
    "loss.item() / max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a9e17-56cd-400a-bd1b-2dff0415f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    accuracy = 0.0\n",
    "\n",
    "    ##############################\n",
    "    #    TRANSFORMER TRAINING    #\n",
    "    ############################## \n",
    "    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        _loss = criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        if not _loss.isnan():\n",
    "            loss += _loss\n",
    "            mask = target_seqs[:, i+1] != 2\n",
    "            accuracy += float((topi.squeeze()[mask] == target_seqs[mask, i+1]).sum() / (target_seqs[mask].size(0)*(target_seqs[mask].size(1)-2)))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print_every = 10\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item() / (target_seqs.size(1)), \"LR\", lr, \"ACCURACY\", _accuracy)\n",
    "\n",
    "    ######################\n",
    "    #   WEIGHTS UPDATE   #\n",
    "    ######################\n",
    "    \n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.to(device), target_seqs.to(device), coordinates.to(device))\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4224ca-ab02-437b-a0ea-5704b1c01daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_sequentially(input_seqs, coordinates)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i, 1:].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i, :-1].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i, 1:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeae19b-77d4-4715-8068-9822af23009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "prediction = list(filter(lambda x: x != '<end>', prediction))\n",
    "prediction = \"\".join(prediction)\n",
    "print(\"MODEL OUTPUT\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141cd30-1b5f-4a10-b844-08b2cbb28576",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequentially(input_seqs[0:3], coordinates[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e1244-c9b2-4f1e-8e7c-58ad12ccd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0:3, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6130ca-cb78-49d1-b167-b6d0817afbbc",
   "metadata": {},
   "source": [
    "## Prediction for permutated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472c7a7-3c27-46d4-ba18-e4cbf9d52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutated_batch(input_seq, coordinates):\n",
    "    seqs = torch.zeros((5, input_seq.size(0))).to(torch.int64)\n",
    "    coords = torch.zeros((5, coordinates.size(0), coordinates.size(1)))\n",
    "    for i in range(5):\n",
    "        idx_permutated = permutate_tokens(input_seq)\n",
    "        seqs[i, :] = input_seq[idx_permutated]\n",
    "        coords[i, :] = coordinates[idx_permutated]\n",
    "    return seqs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272c96c-9ac8-4ea7-9f84-03c28c81db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_permutated, coords_permutated = generate_permutated_batch(input_seqs[0], coordinates[0])\n",
    "input_permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571029b-a0e2-4574-a70e-f02ca965611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequentially(input_permutated, coords_permutated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5daf2-f175-4e54-bdb0-2f9c1844b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983b254-e462-48ce-bc7e-94c2fba39a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
