{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import rnn\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer, embedding\n",
    "from seqgen.datasets.sequences import *\n",
    "from seqgen.datasets.realdata import RealSequencesDataset\n",
    "import random\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "num_layers=4\n",
    "embedding_dim=512\n",
    "batch_size=512\n",
    "max_length=10\n",
    "heads=32\n",
    "dropout=0.1\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "dataset = RealSequencesDataset(filename=\"data/train/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device, use_random=False)\n",
    "dataset_val = RealSequencesDataset(filename=\"data/val/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device, use_random=False)\n",
    "\n",
    "\n",
    "load_from_checkpoint = True\n",
    "checkpoint_file = \"transformer_2023-02-13_17-11-10.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.Transformer(\n",
    "    encoder_embedding_type=embedding.EmbeddingType.COORDS_DIRECT,\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=3,\n",
    "    trg_pad_idx=3,\n",
    "    max_length=max_length,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss(ignore_index=3) # reduction=\"sum\"\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.323533058166504 0.3151041666666667\n"
     ]
    }
   ],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "output = model(input_seqs, target_seqs, coordinates)\n",
    "\n",
    "accuracy = 0.0\n",
    "loss = 0.0\n",
    "for i in range(max_length-1):\n",
    "    topv, topi = output[:, i, :].topk(1)\n",
    "    _loss = criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "    loss += _loss\n",
    "    accuracy += float((topi.squeeze() == target_seqs[:, i+1]).sum()) / (target_seqs.size(0) * (target_seqs.size(1)-1))\n",
    "\n",
    "print(loss.item(), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a97cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.cuda(), target_seqs.cuda(), coordinates.cuda())\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 13.374762535095215 LR 0.001 ACCURACY 0.006874999999999999 ACCURACY_Val 0.0013237847222222223\n",
      "LOSS after epoch 50 13.214398384094238 LR 0.001 ACCURACY 0.32578993055555555 ACCURACY_Val 0.07720486111111109\n",
      "LOSS after epoch 100 13.07995891571045 LR 0.001 ACCURACY 0.3291970486111112 ACCURACY_Val 0.07569010416666666\n",
      "LOSS after epoch 150 12.695701599121094 LR 0.001 ACCURACY 0.333381076388889 ACCURACY_Val 0.0756684027777778\n",
      "LOSS after epoch 200 12.16403579711914 LR 0.001 ACCURACY 0.33809027777777784 ACCURACY_Val 0.07125\n",
      "LOSS after epoch 250 12.164941787719727 LR 0.001 ACCURACY 0.3403168402777777 ACCURACY_Val 0.07113715277777781\n",
      "LOSS after epoch 300 11.88941478729248 LR 0.001 ACCURACY 0.34415364583333335 ACCURACY_Val 0.07014756944444447\n",
      "LOSS after epoch 350 11.602581977844238 LR 0.001 ACCURACY 0.3491710069444444 ACCURACY_Val 0.06879774305555558\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLOSS after epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem(), \u001b[39m\"\u001b[39m\u001b[39mLR\u001b[39m\u001b[39m\"\u001b[39m, lr, \u001b[39m\"\u001b[39m\u001b[39mACCURACY\u001b[39m\u001b[39m\"\u001b[39m, _accuracy, \u001b[39m\"\u001b[39m\u001b[39mACCURACY_Val\u001b[39m\u001b[39m\"\u001b[39m, _accuracy_val)\n\u001b[0;32m     48\u001b[0m \u001b[39m# Compute gradient\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     50\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39m# Update weights of encoder and decoder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benwe\\anaconda3\\envs\\DLCV\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\benwe\\anaconda3\\envs\\DLCV\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "accuracies_val = []\n",
    "\n",
    "for epoch in range(1000):    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    input_seqs_val, coordinates_val, target_seqs_val = dataset_val[0]\n",
    "    \n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    accuracy = 0.0\n",
    "    accuracy_val = 0.0\n",
    "\n",
    "    #####################\n",
    "    #    TRANSFORMER    #\n",
    "    #####################\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs, target_seqs, coordinates)\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        loss += criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        accuracy += float((topi.squeeze() == target_seqs[:, i+1]).sum()) / (target_seqs.size(0) * (target_seqs.size(1)-1))\n",
    "    \n",
    "    predictions = predict_sequentially(input_seqs_val, coordinates_val).cuda()\n",
    "    for i in range(max_length-1):\n",
    "        topi_val = predictions[:, i]\n",
    "        accuracy_val += float((topi_val == target_seqs_val[:, i+1]).sum()) / (target_seqs_val.size(0)*(target_seqs_val.size(1)-1))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    accuracies_val.append(accuracy_val)\n",
    "    \n",
    "    print_every = 50\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        _accuracy_val = sum(accuracies_val[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item(), \"LR\", lr, \"ACCURACY\", _accuracy, \"ACCURACY_Val\", _accuracy_val)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.cuda(), target_seqs.cuda(), coordinates.cuda())\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = RealSequencesDataset(filename=\"data/val/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "predictions = predict_sequentially(input_seqs, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "\n",
    "input = vocab_in.decode_sequence(input_seqs[i].cpu().numpy())\n",
    "output = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "target = vocab_out.decode_sequence(target_seqs[i].cpu().numpy())\n",
    "\n",
    "#input = list(filter(lambda x:(x != '<pad>') and (x != '<start>') and (x != '<end>'), input))\n",
    "#output = list(filter(lambda x: (x != '<pad>'), output))\n",
    "#target = list(filter(lambda x: (x != '<pad>') and (x != '<start>') and (x != '<end>'), target))\n",
    "\n",
    "\n",
    "print(\"MODEL INPUT: \\t\", \" \".join(input))\n",
    "print(\"MODEL OUTPUT: \\t\", \" \".join(output))\n",
    "print(\"TARGET OUTPUT: \\t\", \" \".join(target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "855614792c74907572fb27150ce83cf292ef7ade5f74d6275359b75e1e2c33a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
