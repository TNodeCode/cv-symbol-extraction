{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target_seqs = g.generate_synthetic_training_data(8, max_length=10, device=device, continue_prob=0.997, swap_times=0)\n",
    "input_seqs = torch.Tensor(features[:, :, 0]).to(torch.int64)\n",
    "coordinates = torch.Tensor(features[:, :, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 10, 5]),\n",
       " torch.Size([8, 10]),\n",
       " torch.Size([8, 10, 4]),\n",
       " torch.Size([8, 10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c25b8f-93b5-4493-81e4-fb6c1f3a67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqgen.model import seq2seq_lstm\n",
    "from seqgen.vocabulary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "num_layers=1\n",
    "embedding_dim = 32\n",
    "hidden_size=32\n",
    "batch_size=8\n",
    "max_length=10\n",
    "bidirectional=True\n",
    "\n",
    "load_from_checkpoint = False\n",
    "checkpoint_file = \"model_len25_biy_layers3.pt\"\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "encoder = seq2seq_lstm.EncoderRNN(vocab_size=len(vocab_in), embedding_dim=embedding_dim, num_layers=num_layers, max_length=max_length, hidden_size=hidden_size, bidirectional=bidirectional, pos_encoding=False).to(features.device)\n",
    "#attn = seq2seq_lstm.AdditiveAttention(hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, max_length=max_length).to(features.device)\n",
    "decoder = seq2seq_lstm.DecoderRNN2(embedding_dim=embedding_dim, num_layers=num_layers, max_length=max_length, hidden_size=hidden_size, vocab_size=len(vocab_out), bidirectional=bidirectional, pos_encoding=False).to(features.device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=lr)\n",
    "#attn_optimizer = torch.optim.SGD(attn.parameters(), lr=lr)\n",
    "#positions = seq2seq_lstm.get_position_encoding(max_length, embedding_dim, device=device)\n",
    "positions = seq2seq_lstm.get_coordinate_encoding(coordinates, d=embedding_dim, device=device)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    encoder.load_state_dict(checkpoint['encoder_model_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_model_state_dict'])\n",
    "    encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n",
    "    decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n",
    "    num_layers = checkpoint['num_layers']\n",
    "    embedding_dim = checkpoint['embedding_dim']\n",
    "    hidden_size = checkpoint['hidden_size']\n",
    "    bidirectional = checkpoint['bidirectional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d63a2d8-bced-44ec-b32b-19d5f3055885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run word 1 of all 8 sequences through the encoder\n",
      "Run word 2 of all 8 sequences through the encoder\n",
      "Run word 3 of all 8 sequences through the encoder\n",
      "Run word 4 of all 8 sequences through the encoder\n",
      "Run word 5 of all 8 sequences through the encoder\n",
      "Run word 6 of all 8 sequences through the encoder\n",
      "Run word 7 of all 8 sequences through the encoder\n",
      "Run word 8 of all 8 sequences through the encoder\n",
      "Run word 9 of all 8 sequences through the encoder\n",
      "Run word 10 of all 8 sequences through the encoder\n"
     ]
    }
   ],
   "source": [
    "# Initialize the encoder hidden state and cell state with zeros\n",
    "hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "\n",
    "_hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "encoder_hidden_states = torch.zeros((batch_size, max_length, _hidden_size*num_layers)).to(device)\n",
    "encoder_outputs = torch.zeros((batch_size, max_length, _hidden_size)).to(device)\n",
    "\n",
    "# Iterate over the sequence words and run every word through the encoder\n",
    "for i in range(input_seqs.shape[1]):\n",
    "    # Run the i-th word of the input sequence through the encoder.\n",
    "    # As a result we will get the prediction (output), the hidden state and the cell state.\n",
    "    # The hidden state and cell state will be used as inputs in the next round\n",
    "    print(f\"Run word {i+1} of all {input_seqs.shape[0]} sequences through the encoder\")\n",
    "    output, (hn, cn) = encoder(input_seqs[:, i].unsqueeze(dim=1), coordinates[:, i], positions[:, i:i+1], (hn, cn))\n",
    "    encoder_outputs[:, i:i+1, :] = output\n",
    "    encoder_hidden_states[:, i, :] = seq2seq_lstm.concat_hidden_states(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 64]),\n",
       " torch.Size([2, 8, 32]),\n",
       " torch.Size([2, 8, 32]),\n",
       " torch.Size([8, 10, 64]),\n",
       " torch.Size([8, 10, 64]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hn.shape, cn.shape, encoder_hidden_states.shape, encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29054ba-e5b3-405f-bc5b-149f8862da81",
   "metadata": {},
   "source": [
    "# The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda91121-2c2d-4531-b7ee-d67096698123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run word 1 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 2 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 3 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 4 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 5 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 6 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 7 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 8 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 9 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "Run word 10 through decoder torch.Size([2, 8, 32]) torch.Size([8, 10, 64])\n",
      "LOSS 3.26245231628418\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "\n",
    "# Iterate over words of target sequence and run words through the decoder.\n",
    "# This will produce a prediction for the next word in the sequence\n",
    "for i in range(0, target_seqs.size(1)):\n",
    "    print(f\"Run word {i+1} through decoder\", hn.shape, encoder_hidden_states.shape)\n",
    "    output, (hn, cn), attention = decoder(\n",
    "        x=target_seqs[:, i].unsqueeze(dim=1),\n",
    "        coordinates=coordinates[:, i],\n",
    "        annotations=encoder_hidden_states,\n",
    "        position=positions[:, i:i+1],\n",
    "        hidden=(hn, cn)\n",
    "    )\n",
    "    loss += criterion(output.squeeze(), target_seqs[:, i])\n",
    "\n",
    "print(\"LOSS\", loss.item() / max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02683624-ab59-49b1-b645-105231c21692",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4bb73f-6640-4821-a46a-ceda36ef2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_vector, attention = attn(hn, encoder_hidden_states, logging=True)\n",
    "#context_vector.shape, attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 2.9097002029418944 ACCURACY 0.0037500000558793544\n",
      "LOSS after epoch 10 2.826010894775391 ACCURACY 0.027500000409781934\n",
      "LOSS after epoch 20 2.7654678344726564 ACCURACY 0.05250000115483999\n",
      "LOSS after epoch 30 2.6238496780395506 ACCURACY 0.06875000102445483\n",
      "LOSS after epoch 40 2.6758474349975585 ACCURACY 0.06750000100582838\n",
      "LOSS after epoch 50 2.6237009048461912 ACCURACY 0.027500000409781934\n",
      "LOSS after epoch 60 2.601553535461426 ACCURACY 0.05125000076368451\n",
      "LOSS after epoch 70 2.4524723052978517 ACCURACY 0.06625000098720193\n",
      "LOSS after epoch 80 2.543402671813965 ACCURACY 0.05625000083819032\n",
      "LOSS after epoch 90 2.545836067199707 ACCURACY 0.04625000068917871\n",
      "LOSS after epoch 100 2.5187891006469725 ACCURACY 0.052500000782310964\n",
      "LOSS after epoch 110 2.491815948486328 ACCURACY 0.05625000083819032\n",
      "LOSS after epoch 120 2.487213706970215 ACCURACY 0.06625000098720193\n",
      "LOSS after epoch 130 2.4760505676269533 ACCURACY 0.07125000106170773\n",
      "LOSS after epoch 140 2.323046875 ACCURACY 0.07625000113621354\n",
      "LOSS after epoch 150 2.3646806716918944 ACCURACY 0.07875000117346645\n",
      "LOSS after epoch 160 2.487173652648926 ACCURACY 0.03500000052154064\n",
      "LOSS after epoch 170 2.475261688232422 ACCURACY 0.08125000121071935\n",
      "LOSS after epoch 180 2.46866397857666 ACCURACY 0.037500000558793545\n",
      "LOSS after epoch 190 2.4507686614990236 ACCURACY 0.06625000098720193\n",
      "LOSS after epoch 200 2.377890968322754 ACCURACY 0.07125000106170773\n",
      "LOSS after epoch 210 2.438531684875488 ACCURACY 0.07875000117346645\n",
      "LOSS after epoch 220 2.348374938964844 ACCURACY 0.06250000093132257\n",
      "LOSS after epoch 230 2.4344024658203125 ACCURACY 0.05875000087544322\n",
      "LOSS after epoch 240 2.3466129302978516 ACCURACY 0.08625000128522516\n",
      "LOSS after epoch 250 2.434137153625488 ACCURACY 0.023750000353902578\n",
      "LOSS after epoch 260 2.421927070617676 ACCURACY 0.06000000089406967\n",
      "LOSS after epoch 270 2.3634618759155273 ACCURACY 0.07375000109896064\n",
      "LOSS after epoch 280 2.3817195892333984 ACCURACY 0.07875000117346645\n",
      "LOSS after epoch 290 2.4065134048461916 ACCURACY 0.03375000050291419\n",
      "LOSS after epoch 300 2.4001787185668944 ACCURACY 0.0437500006519258\n",
      "LOSS after epoch 310 2.4091346740722654 ACCURACY 0.07250000108033419\n",
      "LOSS after epoch 320 2.321428108215332 ACCURACY 0.09625000143423676\n",
      "LOSS after epoch 330 2.3782722473144533 ACCURACY 0.0800000011920929\n",
      "LOSS after epoch 340 2.3926265716552733 ACCURACY 0.027500000409781934\n",
      "LOSS after epoch 350 2.3698678970336915 ACCURACY 0.07875000135973095\n",
      "LOSS after epoch 360 2.383578872680664 ACCURACY 0.012500000186264515\n",
      "LOSS after epoch 370 2.3556228637695313 ACCURACY 0.042500000726431605\n",
      "LOSS after epoch 380 2.347208023071289 ACCURACY 0.09125000135973096\n",
      "LOSS after epoch 390 2.3489627838134766 ACCURACY 0.0825000012293458\n",
      "LOSS after epoch 400 2.314319038391113 ACCURACY 0.05000000074505806\n",
      "LOSS after epoch 410 2.3475311279296873 ACCURACY 0.0437500006519258\n",
      "LOSS after epoch 420 2.3398296356201174 ACCURACY 0.0825000012293458\n",
      "LOSS after epoch 430 2.325882339477539 ACCURACY 0.06125000100582838\n",
      "LOSS after epoch 440 2.2586538314819338 ACCURACY 0.09375000167638063\n",
      "LOSS after epoch 450 2.3125003814697265 ACCURACY 0.07000000104308128\n",
      "LOSS after epoch 460 2.261750030517578 ACCURACY 0.10125000160187483\n",
      "LOSS after epoch 470 2.3120609283447267 ACCURACY 0.06000000089406967\n",
      "LOSS after epoch 480 2.303394317626953 ACCURACY 0.09125000163912773\n",
      "LOSS after epoch 490 2.253647232055664 ACCURACY 0.08500000126659871\n",
      "LOSS after epoch 500 2.307330322265625 ACCURACY 0.09875000156462192\n",
      "LOSS after epoch 510 2.2872339248657227 ACCURACY 0.07250000108033419\n",
      "LOSS after epoch 520 2.2918584823608397 ACCURACY 0.037500000558793545\n",
      "LOSS after epoch 530 2.2951860427856445 ACCURACY 0.0700000012293458\n",
      "LOSS after epoch 540 2.2937171936035154 ACCURACY 0.11250000167638063\n",
      "LOSS after epoch 550 2.2888105392456053 ACCURACY 0.013750000204890967\n",
      "LOSS after epoch 560 2.2364477157592773 ACCURACY 0.08875000132247805\n",
      "LOSS after epoch 570 2.297486114501953 ACCURACY 0.05250000087544322\n",
      "LOSS after epoch 580 2.2333658218383787 ACCURACY 0.0675000011920929\n",
      "LOSS after epoch 590 2.2725786209106444 ACCURACY 0.02500000046566129\n",
      "LOSS after epoch 600 2.232274055480957 ACCURACY 0.10125000160187483\n",
      "LOSS after epoch 610 2.2788658142089844 ACCURACY 0.057500000949949025\n",
      "LOSS after epoch 620 2.334071922302246 ACCURACY 0.08875000132247805\n",
      "LOSS after epoch 630 2.2761474609375 ACCURACY 0.10000000158324837\n",
      "LOSS after epoch 640 2.2883338928222656 ACCURACY 0.047500000707805155\n",
      "LOSS after epoch 650 2.293666648864746 ACCURACY 0.08375000124797224\n",
      "LOSS after epoch 660 2.282514762878418 ACCURACY 0.07250000117346644\n",
      "LOSS after epoch 670 2.084195137023926 ACCURACY 0.11125000193715096\n",
      "LOSS after epoch 680 2.261728286743164 ACCURACY 0.08500000135973096\n",
      "LOSS after epoch 690 2.2833602905273436 ACCURACY 0.09625000152736903\n",
      "LOSS after epoch 700 2.2490386962890625 ACCURACY 0.07375000109896064\n",
      "LOSS after epoch 710 2.244152069091797 ACCURACY 0.10250000124797225\n",
      "LOSS after epoch 720 2.26919002532959 ACCURACY 0.10750000160187483\n",
      "LOSS after epoch 730 2.2430694580078123 ACCURACY 0.10000000158324837\n",
      "LOSS after epoch 740 2.2926761627197267 ACCURACY 0.06750000100582838\n",
      "LOSS after epoch 750 2.2289091110229493 ACCURACY 0.08375000134110451\n",
      "LOSS after epoch 760 2.215275764465332 ACCURACY 0.12250000210478902\n",
      "LOSS after epoch 770 2.2140518188476563 ACCURACY 0.04500000067055225\n",
      "LOSS after epoch 780 2.1654052734375 ACCURACY 0.10500000156462193\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(100000):\n",
    "    # With a certain chance present the model the true predictions\n",
    "    # instead of its own predictions in the next iteration\n",
    "    use_teacher_forcing_prob = 0.5\n",
    "    use_teacher_forcing = random.random() < use_teacher_forcing_prob\n",
    "    \n",
    "    # Get a batch of trianing data\n",
    "    features, target_seqs = g.generate_synthetic_training_data(batch_size, max_length=max_length, continue_prob=0.99, device=device, swap_times=0)\n",
    "    features = features.to(device)\n",
    "    target_seqs = target_seqs.to(device)\n",
    "    input_seqs = torch.Tensor(features[:, :, 0]).to(torch.int64)\n",
    "    coordinates = torch.Tensor(features[:, :, 1:])\n",
    "\n",
    "    # Initialize the encoder hidden state and cell state with zeros\n",
    "    hn_enc = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "    cn_enc = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "    \n",
    "    # Initialize encoder outputs tensor\n",
    "    last_n_states = 2 if bidirectional else 1\n",
    "    _hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "    encoder_hidden_states = torch.zeros((batch_size, max_length, _hidden_size*num_layers)).to(device)\n",
    "    encoder_outputs = torch.zeros((batch_size, max_length, _hidden_size)).to(device)\n",
    "    \n",
    "    # Set gradients of all model parameters to zero\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #attn_optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    \n",
    "    ####################\n",
    "    #     ENCODING     #\n",
    "    ####################\n",
    "\n",
    "    # Iterate over the sequence words and run every word through the encoder\n",
    "    for i in range(input_seqs.shape[1]):\n",
    "        # Run the i-th word of the input sequence through the encoder.\n",
    "        # As a result we will get the prediction (output), the hidden state (hn) and the cell state (cn).\n",
    "        # The hidden state and cell state will be used as inputs in the next round\n",
    "        output, (hn_enc, cn_enc) = encoder(\n",
    "            input_seqs[:, i].unsqueeze(dim=1),\n",
    "            coordinates[:, i],\n",
    "            positions[:, i:i+1],\n",
    "            (hn_enc, cn_enc)\n",
    "        )\n",
    "        # Save encoder outputs and states for current word\n",
    "        encoder_outputs[:, i:i+1, :] = output\n",
    "        encoder_hidden_states[:, i, :] = seq2seq_lstm.concat_hidden_states(hn)\n",
    "\n",
    "    ####################\n",
    "    #     DECODING     #\n",
    "    ####################\n",
    "    \n",
    "    accuracy = 0.0\n",
    "\n",
    "    # The first words that we be presented to the model is the '<start>' token\n",
    "    prediction = target_seqs[:, 0]\n",
    "    \n",
    "    # The initial hidden state of the decoder is the final hidden state of the encoder\n",
    "    hn_dec, cn_dec = hn_enc, cn_enc\n",
    "    \n",
    "    # Iterate over words of target sequence and run words through the decoder.\n",
    "    # This will produce a prediction for the next word in the sequence\n",
    "    for i in range(1, target_seqs.size(1)):\n",
    "        # Run word i through decoder and get word i+1 and the new hidden state as outputs\n",
    "        if use_teacher_forcing:\n",
    "            output, (hn_dec, cn_dec), attention = decoder(\n",
    "                x=prediction.unsqueeze(dim=1),\n",
    "                coordinates=coordinates[:, i-1],\n",
    "                annotations=encoder_hidden_states,\n",
    "                position=positions[:, i:i+1],\n",
    "                hidden=(hn_dec, cn_dec)\n",
    "            )\n",
    "        else:\n",
    "            output, (hn_dec, cn_dec), attention = decoder(\n",
    "                x=prediction.unsqueeze(dim=1),\n",
    "                coordinates=coordinates[:, i-1],\n",
    "                annotations=encoder_hidden_states,\n",
    "                position=positions[:, i:i+1],\n",
    "                hidden=(hn_dec, cn_dec)\n",
    "            )\n",
    "\n",
    "            # Get the predicted classes of the model\n",
    "            topv, topi = output.topk(1)\n",
    "            prediction = topi.squeeze()    \n",
    "        loss += criterion(output.squeeze(), target_seqs[:, i])\n",
    "        accuracy += float((prediction == target_seqs[:, i]).sum() / (target_seqs.size(0)*target_seqs.size(1)))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print_every = 10\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item() / (target_seqs.size(1)), \"ACCURACY\", _accuracy)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #attn_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"lr\": lr,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'encoder_model_state_dict': encoder.state_dict(),\n",
    "    'decoder_model_state_dict': decoder.state_dict(),\n",
    "    'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "    'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"history\": history,\n",
    "    \"lr\": lr,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"bidirectional\": bidirectional,\n",
    "}, \"model_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    predictions = torch.zeros(target_seqs.shape)\n",
    "    attention_matrix = torch.zeros((input_seqs.shape[0], input_seqs.shape[1], input_seqs.shape[1]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Initialize the encoder hidden state and cell state with zeros\n",
    "        hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "        cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "        \n",
    "        _hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        last_n_states = 2 if bidirectional else 1\n",
    "        encoder_hidden_states = torch.zeros((input_seqs.shape[0], max_length, _hidden_size)).to(device)\n",
    "        encoder_outputs = torch.zeros((input_seqs.shape[0], max_length, _hidden_size)).to(device)\n",
    "\n",
    "        # Iterate over the sequence words and run every word through the encoder\n",
    "        for i in range(input_seqs.size(1)):\n",
    "            output, (hn, cn) = encoder(\n",
    "                input_seqs[:, i].unsqueeze(dim=1),\n",
    "                coordinates[:, i],\n",
    "                positions[:, i:i+1],\n",
    "                (hn, cn)\n",
    "            )\n",
    "            encoder_outputs[:, i:i+1, :] = output\n",
    "            encoder_hidden_states[:, i:i+1, :] = seq2seq_lstm.concat_hidden_states(hn[-last_n_states:]).unsqueeze(dim=1)\n",
    "\n",
    "        # Predict tokens of the target sequence by running the hidden state through\n",
    "        # the decoder\n",
    "        for i in range(0, target_seqs.size(1)):\n",
    "            output, (hn, cn), attention = decoder(\n",
    "                target_seqs[:, i].unsqueeze(dim=1),\n",
    "                coordinates[:, i],\n",
    "                encoder_hidden_states,\n",
    "                positions[:, i:i+1],\n",
    "                (hn, cn)\n",
    "            )\n",
    "            # Select the indices of the most likely tokens\n",
    "            predicted_char = torch.argmax(output, dim=2)\n",
    "            predictions[:, i] = torch.argmax(output, dim=2).squeeze()\n",
    "            attention_matrix[:, :, i:i+1] = attention\n",
    "        \n",
    "        return predictions, attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4224ca-ab02-437b-a0ea-5704b1c01daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, attention_matrix = predict(input_seqs[0:1], coordinates[0:1], target_seqs[0:1])\n",
    "prediction.shape, attention_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6896f-5818-4718-a584-0aa59e9226de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(attention_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476c3b2-d8ad-4506-8ace-814d9e9eefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_swapped = g.random_swap(input_seqs[0], i=2).unsqueeze(dim=0)\n",
    "coords_swapped = g.random_swap(coordinates[0], i=2).unsqueeze(dim=0)\n",
    "prediction_swapped = predict(in_swapped, coords_swapped, target_seqs[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0408b19-3288-48ac-905b-88eb6ef4017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs[0:1] == in_swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb4a03-69bd-45e1-960f-244da1c18417",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction == prediction_swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions, attention_matrix = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0))\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i][1:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeae19b-77d4-4715-8068-9822af23009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "prediction = list(filter(lambda x: x != '<end>', prediction))\n",
    "prediction = \"\".join(prediction)\n",
    "print(\"MODEL OUTPUT\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b7aff-cecf-476a-bd3c-ae737ff8aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(attention_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05457f9c-56b4-4aaa-ae20-c4e8b120ad62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
