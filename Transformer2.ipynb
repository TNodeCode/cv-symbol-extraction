{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96e719f-18e7-400b-90ed-d5878e5466e6",
   "metadata": {},
   "source": [
    "# Transformer Tutorial\n",
    "\n",
    "based on https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/more_advanced/seq2seq_transformer\n",
    "\n",
    "YouTube: https://www.youtube.com/watch?v=M6adRGJe5cQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694f2e89-978f-4011-8f9a-59520f1cefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torchtext.datasets import Multi30k\n",
    "#from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f2b719-a518-4f8a-9301-69550ca9602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        # src shape (src_len, N)\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "        return src_mask\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        # Extract sequence length and batch size\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "        \n",
    "        # Create tensors that contain hte source and target positions. Expand both tensors to the batch size.\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length).unsqueeze(1).expand(trg_seq_length, N).to(self.device)\n",
    "        )\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, N).to(self.device)\n",
    "        )\n",
    "        \n",
    "        # Run the source sentences and the positions through an embedding layer and then sum them\n",
    "        embed_src = self.dropout(self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        embed_trg = self.dropout(self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        \n",
    "        # Create masks\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_sequence_length).to(self.device)\n",
    "        \n",
    "        # Send all through the transformer to get the predictions\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask\n",
    "        )\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd6e4fb-675c-402e-9a57-35a17381f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training phase\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model=False\n",
    "save_model=True\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs=5\n",
    "learning_rate=3e-4\n",
    "batch_size=32\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size=1000\n",
    "trg_vocab_size=1000\n",
    "embedding_size=512\n",
    "num_heads=8\n",
    "num_encoder_layers=3\n",
    "num_decoder_layers=3\n",
    "dropout=0.1\n",
    "max_len=100\n",
    "forward_expansion=4\n",
    "src_pad_idx=1e6 # this is the index of the <pad> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b191b2-e7c5-48da-bdcc-7c5ad1a0d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1e6\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a546a-fd48-4626-9085-bacd63596907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, batch in enumerate(train_iterator)\n",
    "    in_data = batch.src.to(device)\n",
    "    target = batch.trg.to(device)\n",
    "    \n",
    "    output = model(in_data, target[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
