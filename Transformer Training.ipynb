{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import rnn\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer, embedding\n",
    "from seqgen.datasets.sequences import *\n",
    "from seqgen.datasets.realdata import RealSequencesDataset\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bccbe91c-6286-4398-ad71-ee251ae1af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_dataset=False\n",
    "lr=1e-5\n",
    "num_layers=6\n",
    "embedding_dim=128\n",
    "batch_size=128\n",
    "max_length=50\n",
    "heads=8\n",
    "dropout=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\", vocab_file=\"vocab_in.pkl\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\", vocab_file=\"vocab_out.pkl\")\n",
    "\n",
    "if use_real_dataset:\n",
    "    dataset = RealSequencesDataset(filename=\"data/train/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device)\n",
    "else:\n",
    "    dataset = SyntheticSequenceDataset(vocab_in, vocab_out, max_length, batch_size, continue_prob=0.95, additional_eos=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 51]), torch.Size([128, 51, 4]), torch.Size([128, 51]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be4f2ee2-b6ee-4b52-80c1-9a0f76d147ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,  47,  31,  17,  36, 104,  91, 110,  16,   9,   7, 109,  52,  86,\n",
      "         81, 104,  45, 112,  47,  74,  88,   4,  31, 104,   1,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2], device='cuda:0')\n",
      "tensor([ 0, 59, 63, 85, 20, 74, 20, 97, 48, 20, 87, 23, 70, 20, 78, 20, 59, 53,\n",
      "        23, 98, 65,  3, 96, 23, 78, 23, 75, 78, 20, 16, 66, 20, 83, 86, 65,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "       device='cuda:0')\n",
      "tensor([59, 63, 85, 20, 74, 20, 97, 48, 20, 87, 23, 70, 20, 78, 20, 59, 53, 23,\n",
      "        98, 65,  3, 96, 23, 78, 23, 75, 78, 20, 16, 66, 20, 83, 86, 65,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(input_seqs[0, :-1])\n",
    "print(target_seqs[0, :-1])\n",
    "print(target_seqs[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c23a55-7c29-4a35-b0c4-09dd2a92d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_tokens(input_seq):\n",
    "    # Get the first index where tensor has an SOS or EOS token\n",
    "    sos_idx = list(input_seq).index(0)\n",
    "    eos_idx = list(input_seq).index(1)\n",
    "    # permutate all elements that are not SOS or EOS\n",
    "    idx_permuted = torch.cat([torch.arange(0, sos_idx+1), (torch.randperm(eos_idx - sos_idx - 1) + sos_idx+1), torch.arange(eos_idx, max_length+1)])\n",
    "    return idx_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5e0242-7e39-4644-abd3-aa5b5c87597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 180, tensor(112, device='cuda:0'), tensor(98, device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_checkpoint = False\n",
    "checkpoint_file = \"transformer_temp2.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.PyTorchTransformer(\n",
    "    encoder_embedding_type=embedding.EmbeddingType.COORDS_DIRECT,\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=2,\n",
    "    trg_pad_idx=2,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss(ignore_index=2)\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e27831-a686-4ab8-aa8e-0588faf059c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the feature sequences through the model\n",
    "output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 180]),\n",
       " torch.Size([128, 50, 1]),\n",
       " torch.Size([128, 50, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted classes of the model\n",
    "topv, topi = output.topk(1, dim=2)\n",
    "output.shape, topi.shape, topv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302947998046875"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0.0\n",
    "for i in range(max_length):\n",
    "    _loss = criterion(output[:, i, :], target_seqs[:, i])\n",
    "    if not _loss.isnan():\n",
    "        loss += _loss\n",
    "loss.item() / max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457a9e17-56cd-400a-bd1b-2dff0415f081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 180, tensor(112, device='cuda:0'), tensor(98, device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_in), len(vocab_out), torch.max(input_seqs[:, :-1]), torch.max(target_seqs[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 2.95256072399663 LR 1e-05 ACCURACY 0.001987399298232049\n",
      "LOSS after epoch 100 2.9609802844477633 LR 1e-05 ACCURACY 0.19256766066071576\n",
      "LOSS after epoch 200 2.9139323515050553 LR 1e-05 ACCURACY 0.1921432506706333\n",
      "LOSS after epoch 300 2.9232258516199447 LR 1e-05 ACCURACY 0.19410451809002552\n",
      "LOSS after epoch 400 2.9300839293236827 LR 1e-05 ACCURACY 0.19282348835258745\n",
      "LOSS after epoch 500 2.936972524605545 LR 1e-05 ACCURACY 0.19322228737641126\n",
      "LOSS after epoch 600 2.947541779162837 LR 1e-05 ACCURACY 0.193400424978463\n",
      "LOSS after epoch 700 2.9065234614353552 LR 1e-05 ACCURACY 0.1936121210947749\n",
      "LOSS after epoch 800 2.9167974135454964 LR 1e-05 ACCURACY 0.19291146828676575\n",
      "LOSS after epoch 900 2.9228045893650427 LR 1e-05 ACCURACY 0.19194898122630547\n",
      "LOSS after epoch 1000 2.896685431985294 LR 1e-05 ACCURACY 0.1933470781723736\n",
      "LOSS after epoch 1100 2.9403088139552698 LR 1e-05 ACCURACY 0.19183330473548266\n",
      "LOSS after epoch 1200 2.8698446236404718 LR 1e-05 ACCURACY 0.19331389032071455\n",
      "LOSS after epoch 1300 2.8956161199831496 LR 1e-05 ACCURACY 0.1937285993032856\n",
      "LOSS after epoch 1400 2.832357070025276 LR 1e-05 ACCURACY 0.19438303385133623\n",
      "LOSS after epoch 1500 2.924040252087163 LR 1e-05 ACCURACY 0.1933527559984941\n",
      "LOSS after epoch 1600 2.849523806104473 LR 1e-05 ACCURACY 0.19290187476493884\n",
      "LOSS after epoch 1700 2.8685640821269915 LR 1e-05 ACCURACY 0.19258916517486796\n",
      "LOSS after epoch 1800 2.864058849858303 LR 1e-05 ACCURACY 0.19402615169237833\n",
      "LOSS after epoch 1900 2.8524448170381436 LR 1e-05 ACCURACY 0.19283057265682146\n",
      "LOSS after epoch 2000 2.855545343137255 LR 1e-05 ACCURACY 0.19202968875237275\n",
      "LOSS after epoch 2100 2.8980045692593444 LR 1e-05 ACCURACY 0.1916551358718425\n",
      "LOSS after epoch 2200 2.846701528511795 LR 1e-05 ACCURACY 0.1931738683464937\n",
      "LOSS after epoch 2300 2.818264830346201 LR 1e-05 ACCURACY 0.19258834095031488\n",
      "LOSS after epoch 2400 2.8961833879059435 LR 1e-05 ACCURACY 0.19202092482184527\n",
      "LOSS after epoch 2500 2.8266924689797794 LR 1e-05 ACCURACY 0.1928680783667369\n",
      "LOSS after epoch 2600 2.8613544538909315 LR 1e-05 ACCURACY 0.19257854740280891\n",
      "LOSS after epoch 2700 2.872482000612745 LR 1e-05 ACCURACY 0.19226346742478198\n",
      "LOSS after epoch 2800 2.8965786204618564 LR 1e-05 ACCURACY 0.19362172450637444\n",
      "LOSS after epoch 2900 2.8595207064759496 LR 1e-05 ACCURACY 0.19273933939664858\n",
      "LOSS after epoch 3000 2.857844034830729 LR 1e-05 ACCURACY 0.19218507858051453\n",
      "LOSS after epoch 3100 2.856991038602941 LR 1e-05 ACCURACY 0.1937027094626683\n",
      "LOSS after epoch 3200 2.8619411692899814 LR 1e-05 ACCURACY 0.19202408139535693\n",
      "LOSS after epoch 3300 2.838255938361673 LR 1e-05 ACCURACY 0.19315420664614066\n",
      "LOSS after epoch 3400 2.8574102065142464 LR 1e-05 ACCURACY 0.19239224103570451\n",
      "LOSS after epoch 3500 2.8564991670496322 LR 1e-05 ACCURACY 0.19220245836360847\n",
      "LOSS after epoch 3600 2.8536433799594056 LR 1e-05 ACCURACY 0.19287506209046115\n",
      "LOSS after epoch 3700 2.8936519248812806 LR 1e-05 ACCURACY 0.1933903378812829\n",
      "LOSS after epoch 3800 2.8187378528071383 LR 1e-05 ACCURACY 0.19330959504586645\n",
      "LOSS after epoch 3900 2.8660625382965685 LR 1e-05 ACCURACY 0.19278454618470278\n",
      "LOSS after epoch 4000 2.815678914388021 LR 1e-05 ACCURACY 0.19299709926068317\n",
      "LOSS after epoch 4100 2.8664849973192403 LR 1e-05 ACCURACY 0.19327056079579052\n",
      "LOSS after epoch 4200 2.8502643061619177 LR 1e-05 ACCURACY 0.1928743033570936\n",
      "LOSS after epoch 4300 2.844065647499234 LR 1e-05 ACCURACY 0.19484415200422517\n",
      "LOSS after epoch 4400 2.8623067818435968 LR 1e-05 ACCURACY 0.1922207575419452\n",
      "LOSS after epoch 4500 2.815583172966452 LR 1e-05 ACCURACY 0.19341686363797636\n",
      "LOSS after epoch 4600 2.8837773940142464 LR 1e-05 ACCURACY 0.1920897967973724\n",
      "LOSS after epoch 4700 2.8690179563036153 LR 1e-05 ACCURACY 0.1920021550016827\n",
      "LOSS after epoch 4800 2.8404223872166052 LR 1e-05 ACCURACY 0.19187241653446108\n",
      "LOSS after epoch 4900 2.804202809053309 LR 1e-05 ACCURACY 0.19178103383863346\n",
      "LOSS after epoch 5000 2.856196683995864 LR 1e-05 ACCURACY 0.19299784419650678\n",
      "LOSS after epoch 5100 2.827260933670343 LR 1e-05 ACCURACY 0.19293626160011626\n",
      "LOSS after epoch 5200 2.846735636393229 LR 1e-05 ACCURACY 0.19260262467141728\n",
      "LOSS after epoch 5300 2.8107975978477326 LR 1e-05 ACCURACY 0.19294207271013875\n",
      "LOSS after epoch 5400 2.827095779718137 LR 1e-05 ACCURACY 0.19435033653804568\n",
      "LOSS after epoch 5500 2.8057621974571076 LR 1e-05 ACCURACY 0.19429986583389108\n",
      "LOSS after epoch 5600 2.80408462823606 LR 1e-05 ACCURACY 0.19342716237180865\n",
      "LOSS after epoch 5700 2.819461598115809 LR 1e-05 ACCURACY 0.1924169555027038\n",
      "LOSS after epoch 5800 2.8827128690831803 LR 1e-05 ACCURACY 0.19355806052160915\n",
      "LOSS after epoch 5900 2.8215664134306064 LR 1e-05 ACCURACY 0.19227407603466418\n",
      "LOSS after epoch 6000 2.8403033088235294 LR 1e-05 ACCURACY 0.19220989456691315\n",
      "LOSS after epoch 6100 2.7901823754404105 LR 1e-05 ACCURACY 0.19266083861526567\n",
      "LOSS after epoch 6200 2.8056404263365504 LR 1e-05 ACCURACY 0.19396924205357208\n",
      "LOSS after epoch 6300 2.8089447021484375 LR 1e-05 ACCURACY 0.19171150177600793\n",
      "LOSS after epoch 6400 2.8528559067670036 LR 1e-05 ACCURACY 0.1931721545860637\n",
      "LOSS after epoch 6500 2.7992437026079964 LR 1e-05 ACCURACY 0.19352883220941294\n",
      "LOSS after epoch 6600 2.81695556640625 LR 1e-05 ACCURACY 0.19352384108817205\n",
      "LOSS after epoch 6700 2.7796313715916052 LR 1e-05 ACCURACY 0.19359477915655587\n",
      "LOSS after epoch 6800 2.840572581571691 LR 1e-05 ACCURACY 0.19318450612598098\n",
      "LOSS after epoch 6900 2.8071636125153185 LR 1e-05 ACCURACY 0.19335715142457047\n",
      "LOSS after epoch 7000 2.794543696384804 LR 1e-05 ACCURACY 0.19299458388908533\n",
      "LOSS after epoch 7100 2.8272202435661766 LR 1e-05 ACCURACY 0.1931026042267331\n",
      "LOSS after epoch 7200 2.8331490310968137 LR 1e-05 ACCURACY 0.19265205085044726\n",
      "LOSS after epoch 7300 2.8402482575061274 LR 1e-05 ACCURACY 0.1920799948016065\n",
      "LOSS after epoch 7400 2.8282943426393996 LR 1e-05 ACCURACY 0.19345736466581\n",
      "LOSS after epoch 7500 2.7935488831763173 LR 1e-05 ACCURACY 0.1922289741243003\n",
      "LOSS after epoch 7600 2.7575070250268077 LR 1e-05 ACCURACY 0.19284355971612968\n",
      "LOSS after epoch 7700 2.778171314912684 LR 1e-05 ACCURACY 0.19199251835525502\n",
      "LOSS after epoch 7800 2.781168021407782 LR 1e-05 ACCURACY 0.1932668199070031\n",
      "LOSS after epoch 7900 2.8232320149739585 LR 1e-05 ACCURACY 0.19375296756799798\n",
      "LOSS after epoch 8000 2.81782501819087 LR 1e-05 ACCURACY 0.19318229897704442\n",
      "LOSS after epoch 8100 2.7802557851753984 LR 1e-05 ACCURACY 0.1923711182590341\n",
      "LOSS after epoch 8200 2.7759216906977633 LR 1e-05 ACCURACY 0.19296145647851518\n",
      "LOSS after epoch 8300 2.791926066080729 LR 1e-05 ACCURACY 0.1930237501655938\n",
      "LOSS after epoch 8400 2.7970733642578125 LR 1e-05 ACCURACY 0.19298500340199098\n",
      "LOSS after epoch 8500 2.7372544232536766 LR 1e-05 ACCURACY 0.19330690174538176\n",
      "LOSS after epoch 8600 2.8209075927734375 LR 1e-05 ACCURACY 0.192738630027161\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    accuracy = 0.0\n",
    "\n",
    "    ##############################\n",
    "    #    TRANSFORMER TRAINING    #\n",
    "    ############################## \n",
    "    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        _loss = criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        if not _loss.isnan():\n",
    "            loss += _loss\n",
    "            mask = target_seqs[:, i+1] != 2\n",
    "            accuracy += float((topi.squeeze()[mask] == target_seqs[mask, i+1]).sum() / (target_seqs[mask].size(0)*(target_seqs[mask].size(1)-2)))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print_every = 100\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item() / (target_seqs.size(1)), \"LR\", lr, \"ACCURACY\", _accuracy)\n",
    "\n",
    "    ######################\n",
    "    #   WEIGHTS UPDATE   #\n",
    "    ######################\n",
    "    \n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    'model_type': type(model),\n",
    "    \"history\": history,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'model_type': type(model),\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.to(device), target_seqs.to(device), coordinates.to(device))\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4224ca-ab02-437b-a0ea-5704b1c01daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict_sequentially(input_seqs, coordinates)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INPUT ['<unk>', '<unk>', '<unk>', 'q', 'b', '<unk>', '<unk>', 'U', 'H', 't', 'v', 'T', 'i', 'w', 'I', 'a', 'd', 'H', 'q', 'R', '<end>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "MODEL OUTPUT ['/', '^', '_', '\\\\cdot', '^', '/', '^', '^', '^', '/', '^', 'q', '^', '\\\\cdot', '^', '/', '^', '/', '^', '^', '/', '^', '/', '^', '^', '\\\\cdot', '_', '/', '^', '^', '\\\\cdot', '_', '/', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^', '^']\n",
      "TARGET OUTPUT ['I', 'R', '_', 'v', '_', 'H', 'q', 'T', '_', '\\\\cdot', '^', 't', '^', '\\\\cdot', '^', 'U', '^', 'q', '/', '^', 'w', '_', 'H', '/', '_', 'i', '^', '-', 'a', '^', 'd', '_', 'b', '<end>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i, 1:].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i, :-1].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i, 1:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deeae19b-77d4-4715-8068-9822af23009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT /^_\\cdot^/^^^/^q^\\cdot^/^/^^/^/^^\\cdot_/^^\\cdot_/^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "prediction = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "prediction = list(filter(lambda x: x != '<end>', prediction))\n",
    "prediction = \"\".join(prediction)\n",
    "print(\"MODEL OUTPUT\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4141cd30-1b5f-4a10-b844-08b2cbb28576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[60, 60, 60, 60, 20, 60, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sequentially(input_seqs[0:3], coordinates[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130e1244-c9b2-4f1e-8e7c-58ad12ccd273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[93,  5, 88, 62, 23, 95, 78, 20, 53, 81, 20, 88, 10, 20, 60, 60, 20,  8,\n",
       "         23, 74, 72, 71, 65, 33, 80,  8, 20, 59, 49, 92,  1,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [75, 56, 20, 58, 57, 20,  5, 55, 81, 20, 83, 48, 91, 95, 91, 23, 86, 23,\n",
       "         76, 48, 23, 88, 52, 20, 69, 65, 92, 63, 20, 52, 23,  8, 20, 96, 96, 90,\n",
       "         23, 16, 23, 75,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [58, 23, 11, 23, 93, 20, 90, 87, 23, 57, 65, 20, 32, 20, 94, 92, 23, 60,\n",
       "         88, 69, 83, 23, 53, 94, 20, 79, 54, 20, 63, 20, 66, 94, 85, 20, 96, 20,\n",
       "         54, 20, 59, 87, 71, 58, 23, 70, 80,  5, 23, 33,  1,  2]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seqs[0:3, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6130ca-cb78-49d1-b167-b6d0817afbbc",
   "metadata": {},
   "source": [
    "## Prediction for permutated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3472c7a7-3c27-46d4-ba18-e4cbf9d52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutated_batch(input_seq, coordinates):\n",
    "    seqs = torch.zeros((5, input_seq.size(0))).to(torch.int64)\n",
    "    coords = torch.zeros((5, coordinates.size(0), coordinates.size(1)))\n",
    "    for i in range(5):\n",
    "        idx_permutated = permutate_tokens(input_seq)\n",
    "        seqs[i, :] = input_seq[idx_permutated]\n",
    "        coords[i, :] = coordinates[idx_permutated]\n",
    "    return seqs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a272c96c-9ac8-4ea7-9f84-03c28c81db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 108,  44,  47, 107,  36, 104,  34,  38,  93,  91,  70,   6,  44,\n",
       "          34,  31,  85,  13,  30,  93,  99,  79,   2,  53,   1,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
       "        [  0,  34, 108, 104,  44,  85,  30,  13,  93,  44,  34,  31,  93,  91,\n",
       "         107,  47,  38,  99,   6,  70,   2,  53,  79,  36,   1,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
       "        [  0,  30,  47,   6,  70,  93,  36,  13,  34,  91,  79,  38,  93,  34,\n",
       "         108,   2,  44, 104, 107,  99,  53,  85,  31,  44,   1,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
       "        [  0,  93,  99,  34,  30,  79,  34,  13, 104,  70,  44,  38, 107,  93,\n",
       "           2,  31,  53,  85,  44,   6,  91,  36, 108,  47,   1,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
       "        [  0, 108, 104,  53,  44,   6,  30,  91,   2, 107,  99,  79,  13,  85,\n",
       "          36,  93,  44,  47,  70,  93,  38,  31,  34,  34,   1,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_permutated, coords_permutated = generate_permutated_batch(input_seqs[0], coordinates[0])\n",
    "input_permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7571029b-a0e2-4574-a70e-f02ca965611b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [20, 20, 20, 20, 20, 60, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [60, 20, 60, 60, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0],\n",
       "        [20, 60, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sequentially(input_permutated, coords_permutated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67c5daf2-f175-4e54-bdb0-2f9c1844b87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([93,  5, 88, 62, 23, 95, 78, 20, 53, 81, 20, 88, 10, 20, 60, 60, 20,  8,\n",
       "        23, 74, 72, 71, 65, 33, 80,  8, 20, 59, 49, 92,  1,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seqs[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983b254-e462-48ce-bc7e-94c2fba39a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
