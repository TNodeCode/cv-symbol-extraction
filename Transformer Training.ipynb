{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import seq2seq_lstm\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer\n",
    "from seqgen.datasets.sequences import *\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccbe91c-6286-4398-ad71-ee251ae1af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "num_layers=1\n",
    "embedding_dim=64\n",
    "batch_size=512\n",
    "max_length=50\n",
    "heads=8\n",
    "dropout=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "dataset = SyntheticSequenceDataset(vocab_in, vocab_out, max_length, batch_size, continue_prob=0.95, additional_eos=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\PycharmProjects\\UdacityProjects\\YoloImagePreparation\\seqgen\\datasets\\sequences.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_seqs = torch.tensor(features[:, :, 0]).to(torch.int64)\n",
      "C:\\Users\\tilof\\PycharmProjects\\UdacityProjects\\YoloImagePreparation\\seqgen\\datasets\\sequences.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coordinates = torch.tensor(features[:, :, 1:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 51]), torch.Size([512, 51, 4]), torch.Size([512, 51]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4f2ee2-b6ee-4b52-80c1-9a0f76d147ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 6, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n",
      "tensor([ 0,  8,  3, 16,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([ 8,  3, 16,  6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n"
     ]
    }
   ],
   "source": [
    "print(input_seqs[0, :-1])\n",
    "print(target_seqs[0, :-1])\n",
    "print(target_seqs[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c23a55-7c29-4a35-b0c4-09dd2a92d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_tokens(input_seq):\n",
    "    # Get the first index where tensor has an SOS or EOS token\n",
    "    sos_idx = list(input_seq).index(0)\n",
    "    eos_idx = list(input_seq).index(1)\n",
    "    # permutate all elements that are not SOS or EOS\n",
    "    idx_permuted = torch.cat([torch.arange(0, sos_idx+1), (torch.randperm(eos_idx - sos_idx - 1) + sos_idx+1), torch.arange(eos_idx, max_length+1)])\n",
    "    return idx_permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_checkpoint = False\n",
    "checkpoint_file = \"model_2023-01-15_09-17-53.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.TransformerCoordsEmbedding(\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=1e10,\n",
    "    trg_pad_idx=1e10,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e27831-a686-4ab8-aa8e-0588faf059c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Run the feature sequences through the model\n",
    "output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 50, 25]), torch.Size([512, 50, 1]), torch.Size([512, 50, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted classes of the model\n",
    "topv, topi = output.topk(1, dim=2)\n",
    "output.shape, topi.shape, topv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3377059936523437"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0.0\n",
    "for i in range(max_length):\n",
    "    loss += criterion(output[:, i, :], target_seqs[:, i])\n",
    "loss.item() / max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 3.2900887283624387 LR 0.01 ACCURACY 0.0012236926217155998\n",
      "LOSS after epoch 10 1.2612539553174786 LR 0.01 ACCURACY 0.575003988732351\n",
      "LOSS after epoch 20 1.1368521148083257 LR 0.01 ACCURACY 0.5967952807317488\n",
      "LOSS after epoch 30 1.1732073765175015 LR 0.01 ACCURACY 0.5990593113237992\n",
      "LOSS after epoch 40 1.1913992937873392 LR 0.01 ACCURACY 0.6000996500370093\n",
      "LOSS after epoch 50 1.1376882814893536 LR 0.01 ACCURACY 0.5997688134782948\n",
      "LOSS after epoch 60 1.2432478362438726 LR 0.01 ACCURACY 0.5972576544620096\n",
      "LOSS after epoch 70 1.164559383018344 LR 0.01 ACCURACY 0.5984375003026798\n",
      "LOSS after epoch 80 1.1613398533241421 LR 0.01 ACCURACY 0.6027901793131605\n",
      "LOSS after epoch 90 1.1594913707059973 LR 0.01 ACCURACY 0.6049226727336645\n",
      "LOSS after epoch 100 1.136198455212163 LR 0.01 ACCURACY 0.5993901461537462\n",
      "LOSS after epoch 110 1.1661632014255898 LR 0.01 ACCURACY 0.6007214608951472\n",
      "LOSS after epoch 120 1.1874961105047488 LR 0.01 ACCURACY 0.6037189101334661\n",
      "LOSS after epoch 130 1.1188652936150045 LR 0.01 ACCURACY 0.6151267548440955\n",
      "LOSS after epoch 140 1.1684483546836704 LR 0.01 ACCURACY 0.608856824983377\n",
      "LOSS after epoch 150 1.1329082414215685 LR 0.01 ACCURACY 0.6078204716439359\n",
      "LOSS after epoch 160 1.1207807952282476 LR 0.01 ACCURACY 0.6096420606132597\n",
      "LOSS after epoch 170 1.1728073568905102 LR 0.01 ACCURACY 0.602228157396894\n",
      "LOSS after epoch 180 1.0887549905215992 LR 0.01 ACCURACY 0.610801977844676\n",
      "LOSS after epoch 190 1.1531389273849189 LR 0.01 ACCURACY 0.6053930164431222\n",
      "LOSS after epoch 200 1.1798959619858687 LR 0.01 ACCURACY 0.6075175378122367\n",
      "LOSS after epoch 210 1.302630106608073 LR 0.01 ACCURACY 0.6006337692611851\n",
      "LOSS after epoch 220 1.1968485514322917 LR 0.01 ACCURACY 0.6080556430621072\n",
      "LOSS after epoch 230 1.1562534407073377 LR 0.01 ACCURACY 0.6018335459637456\n",
      "LOSS after epoch 240 1.1606018963982077 LR 0.01 ACCURACY 0.6097815689747221\n",
      "LOSS after epoch 250 1.179463554831112 LR 0.01 ACCURACY 0.6066406272933819\n",
      "LOSS after epoch 260 1.1237803440467984 LR 0.01 ACCURACY 0.607250478543574\n",
      "LOSS after epoch 270 1.1837032542509192 LR 0.01 ACCURACY 0.6097417102311737\n",
      "LOSS after epoch 280 1.1828749413583792 LR 0.01 ACCURACY 0.6045719084562734\n",
      "LOSS after epoch 290 1.2193156971650965 LR 0.01 ACCURACY 0.6075932700070552\n",
      "LOSS after epoch 300 1.1265071046118642 LR 0.01 ACCURACY 0.6085618629818782\n",
      "LOSS after epoch 310 1.1185922809675628 LR 0.01 ACCURACY 0.6075892867520452\n",
      "LOSS after epoch 320 1.176023146685432 LR 0.01 ACCURACY 0.6099968137452378\n",
      "LOSS after epoch 330 1.131306292963963 LR 0.01 ACCURACY 0.609239477047231\n",
      "LOSS after epoch 340 1.2095370573156021 LR 0.01 ACCURACY 0.607198661705479\n",
      "LOSS after epoch 350 1.167882059134689 LR 0.01 ACCURACY 0.5972815694171004\n",
      "LOSS after epoch 360 1.1372495165058212 LR 0.01 ACCURACY 0.6097656243364327\n",
      "LOSS after epoch 370 1.1423597148820466 LR 0.01 ACCURACY 0.6089365431340411\n",
      "LOSS after epoch 380 1.1686256259095436 LR 0.01 ACCURACY 0.6107461739331483\n",
      "LOSS after epoch 390 1.1215370028626686 LR 0.01 ACCURACY 0.6078643173794263\n",
      "LOSS after epoch 400 1.2036678089815027 LR 0.01 ACCURACY 0.6104033806594089\n",
      "LOSS after epoch 410 1.091386084463082 LR 0.01 ACCURACY 0.6071069839526899\n",
      "LOSS after epoch 420 1.145181842878753 LR 0.01 ACCURACY 0.6077527105342597\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOSS after epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m (target_seqs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCURACY\u001b[39m\u001b[38;5;124m\"\u001b[39m, _accuracy)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Compute gradient\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Update weights of encoder and decoder\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(50000):    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    \n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    #####################\n",
    "    #    TRANSFORMER    #\n",
    "    #####################\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs[:, :-1], target_seqs[:, :-1], coordinates[:, :-1])\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        loss += criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        accuracy += float((topi.squeeze() == target_seqs[:, i+1]).sum() / (target_seqs.size(0)*(target_seqs.size(1)-2)))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print_every = 10\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item() / (target_seqs.size(1)), \"LR\", lr, \"ACCURACY\", _accuracy)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"history\": history,\n",
    "    \"lr\": lr,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        coordinate_encoding = seq2seq_lstm.get_coordinate_encoding(coordinates, d=embedding_dim, max_length=max_length)\n",
    "        output = model(input_seqs, target_seqs, coordinate_encoding)\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4224ca-ab02-437b-a0ea-5704b1c01daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_sequentially(input_seqs, coordinates)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "import random\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = predict(input_seqs, coordinates, target_seqs)\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i, 1:].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i, :-1].cpu().numpy()))\n",
    "print(\"TARGET OUTPUT\", vocab_out.decode_sequence(target_seqs[i, 1:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeae19b-77d4-4715-8068-9822af23009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "prediction = list(filter(lambda x: x != '<end>', prediction))\n",
    "prediction = \"\".join(prediction)\n",
    "print(\"MODEL OUTPUT\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141cd30-1b5f-4a10-b844-08b2cbb28576",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequentially(input_seqs[0:3], coordinates[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e1244-c9b2-4f1e-8e7c-58ad12ccd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0:3, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6130ca-cb78-49d1-b167-b6d0817afbbc",
   "metadata": {},
   "source": [
    "## Prediction for permutated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472c7a7-3c27-46d4-ba18-e4cbf9d52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutated_batch(input_seq, coordinates):\n",
    "    seqs = torch.zeros((5, input_seq.size(0))).to(torch.int64)\n",
    "    coords = torch.zeros((5, coordinates.size(0), coordinates.size(1)))\n",
    "    for i in range(5):\n",
    "        idx_permutated = permutate_tokens(input_seq)\n",
    "        seqs[i, :] = input_seq[idx_permutated]\n",
    "        coords[i, :] = coordinates[idx_permutated]\n",
    "    return seqs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272c96c-9ac8-4ea7-9f84-03c28c81db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_permutated, coords_permutated = generate_permutated_batch(input_seqs[0], coordinates[0])\n",
    "input_permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571029b-a0e2-4574-a70e-f02ca965611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequentially(input_permutated, coords_permutated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5daf2-f175-4e54-bdb0-2f9c1844b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983b254-e462-48ce-bc7e-94c2fba39a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
