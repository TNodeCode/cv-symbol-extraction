{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seqgen.model import rnn\n",
    "from seqgen.vocabulary import *\n",
    "from seqgen.model import transformer, embedding\n",
    "from seqgen.datasets.sequences import *\n",
    "from seqgen.datasets.realdata import RealSequencesDataset\n",
    "import random\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "num_layers=3\n",
    "embedding_dim=256\n",
    "batch_size=512\n",
    "max_length=10\n",
    "heads=16\n",
    "dropout=0\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "dataset = RealSequencesDataset(filename=\"data/train/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device, use_random=False)\n",
    "dataset_val = RealSequencesDataset(filename=\"data/val/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device, use_random=False)\n",
    "\n",
    "\n",
    "load_from_checkpoint = False\n",
    "checkpoint_file = \"transformer_2023-02-13_17-11-10.pt\"\n",
    "\n",
    "# Transformer model\n",
    "model = transformer.Transformer(\n",
    "    encoder_embedding_type=embedding.EmbeddingType.COORDS_DIRECT,\n",
    "    src_vocab_size=len(vocab_in),\n",
    "    trg_vocab_size=len(vocab_out),\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    src_pad_idx=3,\n",
    "    trg_pad_idx=3,\n",
    "    max_length=max_length,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, gamma=0.95)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss(ignore_index=3) # reduction=\"sum\"\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd81330-0cf9-4ac9-a900-1a3ebbbba760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.560237884521484 0.001953125\n"
     ]
    }
   ],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0]\n",
    "output = model(input_seqs, target_seqs, coordinates)\n",
    "\n",
    "accuracy = 0.0\n",
    "loss = 0.0\n",
    "for i in range(max_length-1):\n",
    "    topv, topi = output[:, i, :].topk(1)\n",
    "    _loss = criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "    loss += _loss\n",
    "    accuracy += float((topi.squeeze() == target_seqs[:, i+1]).sum()) / (target_seqs.size(0) * (target_seqs.size(1)-1))\n",
    "\n",
    "print(loss.item(), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a97cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.cuda(), target_seqs.cuda(), coordinates.cuda())\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c59e1-3885-4a12-8696-9fcf3da9cf9e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 48.520843505859375 LR 0.001 ACCURACY 4.340277777777778e-05 ACCURACY_Val 0.00047743055555555554\n",
      "LOSS after epoch 50 9.066449165344238 LR 0.001 ACCURACY 0.28011284722222224 ACCURACY_Val 0.1470486111111111\n",
      "LOSS after epoch 100 2.9636106491088867 LR 0.001 ACCURACY 0.5030642361111112 ACCURACY_Val 0.23713541666666665\n",
      "LOSS after epoch 150 1.4647239446640015 LR 0.001 ACCURACY 0.5767057291666666 ACCURACY_Val 0.2663541666666666\n",
      "LOSS after epoch 200 1.57945716381073 LR 0.001 ACCURACY 0.549609375 ACCURACY_Val 0.24414930555555558\n",
      "LOSS after epoch 250 0.7474979162216187 LR 0.001 ACCURACY 0.6095138888888888 ACCURACY_Val 0.26813368055555564\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "accuracies = []\n",
    "accuracies_val = []\n",
    "\n",
    "for epoch in range(300):    \n",
    "    # Get a batch of training data\n",
    "    input_seqs, coordinates, target_seqs = dataset[0]\n",
    "    input_seqs_val, coordinates_val, target_seqs_val = dataset_val[0]\n",
    "    \n",
    "    # Set gradients of all model parameters to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    accuracy = 0.0\n",
    "    accuracy_val = 0.0\n",
    "\n",
    "    #####################\n",
    "    #    TRANSFORMER    #\n",
    "    #####################\n",
    "    \n",
    "    # Run the input sequences through the model\n",
    "    output = model(input_seqs, target_seqs, coordinates)\n",
    "    \n",
    "    # Iterate over sequence positions to compute the loss\n",
    "    for i in range(max_length-1):\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output[:, i, :].topk(1)\n",
    "        loss += criterion(output[:, i, :], target_seqs[:, i+1])\n",
    "        accuracy += float((topi.squeeze() == target_seqs[:, i+1]).sum()) / (target_seqs.size(0) * (target_seqs.size(1)-1))\n",
    "    \n",
    "    predictions = predict_sequentially(input_seqs_val, coordinates_val).cuda()\n",
    "    for i in range(max_length-1):\n",
    "        topi_val = predictions[:, i]\n",
    "        accuracy_val += float((topi_val == target_seqs_val[:, i+1]).sum()) / (target_seqs_val.size(0)*(target_seqs_val.size(1)-1))\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "    accuracies_val.append(accuracy_val)\n",
    "    \n",
    "    print_every = 50\n",
    "    if not epoch % print_every:\n",
    "        _accuracy = sum(accuracies[-print_every:]) / print_every\n",
    "        _accuracy_val = sum(accuracies_val[-print_every:]) / print_every\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"LOSS after epoch {epoch}\", loss.item(), \"LR\", lr, \"ACCURACY\", _accuracy, \"ACCURACY_Val\", _accuracy_val)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "    accuracy = 0.0\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    optimizer.step()\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"lr\": lr,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_length\": max_length,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"heads\": heads,\n",
    "    \"dropout\": dropout,\n",
    "}, \"transformer_\" + date_time + \".pt\")\n",
    "\n",
    "\n",
    "with open(\"training_\" + date_time + '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_seqs, coordinates, target_seqs):\n",
    "    vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "    vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seqs.cuda(), target_seqs.cuda(), coordinates.cuda())\n",
    "        # Get the predicted classes of the model\n",
    "        topv, topi = output.topk(1, dim=2)\n",
    "        \n",
    "        return topi.squeeze()\n",
    "    \n",
    "def predict_sequentially(input_seqs, coordinates):\n",
    "    prediction = torch.zeros((input_seqs.size(0), input_seqs.size(1)-1)).to(torch.int64)\n",
    "    for i in range(max_length-1):\n",
    "        output = predict(input_seqs, coordinates, prediction)\n",
    "        prediction[:, i] = output[:, i]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e93ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = RealSequencesDataset(filename=\"data/val/label.txt\", vocab_in=vocab_in, vocab_out=vocab_out, max_length=max_length-1, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc8c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs, coordinates, target_seqs = dataset[0] # training set / dataset_val[0] validation set\n",
    "predictions = predict_sequentially(input_seqs, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INPUT: \t x - y\n",
      "MODEL OUTPUT: \t x - y <end> <end> <end> <end> <end> <end>\n",
      "TARGET OUTPUT: \t x - y\n"
     ]
    }
   ],
   "source": [
    "# Pick random sequence and its prediction from the model\n",
    "\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "i = random.randint(0, predictions.size(0)-1)\n",
    "\n",
    "input = vocab_in.decode_sequence(input_seqs[i].cpu().numpy())\n",
    "output = vocab_out.decode_sequence(predictions[i].cpu().numpy())\n",
    "target = vocab_out.decode_sequence(target_seqs[i].cpu().numpy())\n",
    "\n",
    "input = list(filter(lambda x:(x != '<pad>') and (x != '<start>') and (x != '<end>'), input))\n",
    "output = list(filter(lambda x: (x != '<pad>'), output))\n",
    "target = list(filter(lambda x: (x != '<pad>') and (x != '<start>') and (x != '<end>'), target))\n",
    "\n",
    "\n",
    "print(\"MODEL INPUT: \\t\", \" \".join(input))\n",
    "print(\"MODEL OUTPUT: \\t\", \" \".join(output))\n",
    "print(\"TARGET OUTPUT: \\t\", \" \".join(target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "855614792c74907572fb27150ce83cf292ef7ade5f74d6275359b75e1e2c33a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
