{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307e370c-40cb-4194-bf97-ad9e9ab745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seqgen.seq_gen as g\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197faa56-4d2f-4453-bbda-32c5b4115b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78d88d5-47ef-4b8f-9d41-e1d8fb70c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target_seqs = g.generate_synthetic_training_data(3, max_length=10, device=device)\n",
    "input_seqs = torch.Tensor(features[:, :, 0]).to(torch.int64)\n",
    "coordinates = torch.Tensor(features[:, :, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437f41f6-057b-41e5-9d52-1744666d4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 5]),\n",
       " torch.Size([3, 10]),\n",
       " torch.Size([3, 10, 4]),\n",
       " torch.Size([3, 10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, input_seqs.shape, coordinates.shape, target_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3288c872-f5fa-4510-a1a0-6937955777df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  6,  9, 12,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 11, 13, 12, 12,  4,  8,  6,  7,  1],\n",
       "        [ 0,  3,  1,  1,  1,  1,  1,  1,  1,  1]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first three encoded input sequences\n",
    "input_seqs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ec1852-a509-4bbb-96e3-6e18f04d0139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4963, 0.5521, 0.7857, 0.9137],\n",
       "        [0.6651, 0.6081, 0.9589, 1.0000],\n",
       "        [0.7272, 0.6422, 1.0000, 0.9667],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the coordinates of the tokens of the first input sequence\n",
    "coordinates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e726fd55-586e-43e0-a8bb-2f508dd0a538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  6,  9, 12,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 11, 13, 12, 12,  4,  8,  6,  7,  1],\n",
       "        [ 0,  3,  1,  1,  1,  1,  1,  1,  1,  1]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first three encoded output sequences\n",
    "target_seqs[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e0ccc-ca5b-40fa-81f5-303ec14d8122",
   "metadata": {},
   "source": [
    "## Embedding Layer\n",
    "\n",
    "The embedding layers maps each token to a vector space of dimension $\\mathbb{R}^{D_{emb}}$.\n",
    "If we have an input sequence `[5,3,4]` and $D_{emb} = 2$ the output may look like this: `[[0.319, 0.841], [0.781, 0.682], [0.432,0.968]]`.\n",
    "\n",
    "The embedding layer expects an input sequence of type `int` where each integer in the input sequence represents a class. The total number of distinct possible classes of the input sequence is called the vocabulary size $N_{vocab}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2108243-7c86-40f0-9aaa-f05b03a02719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = torch.nn.Embedding(num_embeddings=17, embedding_dim=2).to(device)\n",
    "x_emb = emb(input_seqs)\n",
    "x_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c784b8e-d48f-41d8-a649-fbc9a77e0795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0152,  0.6046],\n",
       "        [ 2.5122, -0.5076],\n",
       "        [-0.0699, -1.7749],\n",
       "        [ 0.8289, -0.3582],\n",
       "        [-0.4849,  0.2877],\n",
       "        [-0.4849,  0.2877],\n",
       "        [-0.4849,  0.2877],\n",
       "        [-0.4849,  0.2877],\n",
       "        [-0.4849,  0.2877],\n",
       "        [-0.4849,  0.2877]], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show embedding of first input sequence\n",
    "x_emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243fbc0-7f29-4052-be95-48deca5693aa",
   "metadata": {},
   "source": [
    "## LSTM Layer\n",
    "\n",
    "The LSTM layer implements recursion in a neural net. It will need three hyperparameters:\n",
    "- **input_size**: This is the dimension of the input vectors that are run through the LSTM layer. If the vectors have been run to an embedding layer before input_size must be equal to the argument embedding_dim of the embedding layer\n",
    "- **hidden_size**: This is the dimension of the internal state vector $h_n$, which is identical to the dimension of the cell state $c_n$ and the dimension of the output vectors $out$. The hidden size can be freely chosen by you. Small values for hidden_size may leed to underfitting, but large values can cause overfitting.\n",
    "- **num_layers**: This parameter defines how many layers of LSTMs are stacked in the network. The more layers you stack the more complex patterns the LSTM is able to model, but this also comes with te risk of overfitting the data.\n",
    "\n",
    "There is also another important parameter:\n",
    "- **batch_first**: If the input tensor of the LSTM layer is of shape `(batch_size, sequence_length, embedding_dim)` you will have to set this parameter to True. Otherwise if the input is of shape `(sequence_length, embedding_dim, batch_size)` you will have to set this parameter to false.\n",
    "\n",
    "Now let's look at the outputs of the LSTM layer:\n",
    "- **output**: This is the predicted tensor of the LSTM layer which will be passed to the next layer. You may add a linear classification and a softmax layer after the LSTM layer. The output tensor is of shape `(batch_size, sequence_length, hidden_size)` if `batch_first` is set to true.\n",
    "- **h_n**: Hidden state, tensor of shape `(num_layers, batch_size, hidden_size)`\n",
    "- **c_n**: Cell state, tensor of shape `(num_layers, batch_size, hidden_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37afe240-626b-41fd-aa43-621c531bdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=4\n",
    "lstm = torch.nn.LSTM(input_size=2, hidden_size=hidden_size, num_layers=7, batch_first=True).to(device)\n",
    "lstm_output, (h_n, c_n) = lstm(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3408b76e-1418-4648-9ad6-c97780f86c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 4]), torch.Size([7, 3, 4]), torch.Size([7, 3, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output.shape, h_n.shape, c_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2b09f-9782-4993-84f6-c059d98e246e",
   "metadata": {},
   "source": [
    "## Linear classifier\n",
    "\n",
    "After the tensors have been passed trough the LSTM layer it is time to implement a classification of these tensors. The linear layer's task is to take the output of the LSTM layer and map it to the output classes. In language models these classes would be the characters or words of the output vocabulary. There are two hyperparameters of the linear layer that we have to set:\n",
    "\n",
    "- **in_features**: This is the dimension of the vectors that represent the words in our sequences. When these vectors come from an LSTM layer the dimension of the input features is equal to the hidden_size value of the LSTM layer.\n",
    "- **out_features**: The dimension of the output vectors of the linear layer is equal to the number of characters / words of our output vocabulary. If we want to produce englisch sentences with our model and there are 5000 possible words in our vocabulary this parameter's value would be 5000.\n",
    "\n",
    "The output of the linear layer is of shape `(batch_size, sequence_length, target_vocab_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3199b7a1-7a9c-4503-a73c-8e9712b6b28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 5000\n",
    "linear = torch.nn.Linear(in_features=hidden_size, out_features=output_size).to(device)\n",
    "linear_output = linear(lstm_output)\n",
    "linear_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ac623-fd3d-4722-aa21-5bb4efc4b3f2",
   "metadata": {},
   "source": [
    "## Softmax function\n",
    "\n",
    "The purpose of the softmax layer is to compute a probability for each position and each word of the output vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123acfab-8a23-4ecc-b9d4-67207e617f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.LogSoftmax(dim=1)\n",
    "softmax_output = softmax(linear_output)\n",
    "softmax_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae84cc-67fe-4487-b119-51c1e6563d7c",
   "metadata": {},
   "source": [
    "# The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c25b8f-93b5-4493-81e4-fb6c1f3a67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqgen.model import seq2seq_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7974696-6918-47ff-93b7-14cc4517dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "embedding_dim = 20\n",
    "hidden_size=20\n",
    "\n",
    "encoder = seq2seq_lstm.EncoderRNN(vocab_size=17, embedding_dim=embedding_dim, hidden_size=hidden_size).to(features.device)\n",
    "decoder = seq2seq_lstm.DecoderRNN(hidden_size=hidden_size, vocab_size=23).to(features.device)\n",
    "\n",
    "# Initialize optimizer for encoder and decoder\n",
    "encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=lr)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d63a2d8-bced-44ec-b32b-19d5f3055885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run word 1 of all 500 sequences through the encoder\n",
      "Run word 2 of all 500 sequences through the encoder\n",
      "Run word 3 of all 500 sequences through the encoder\n",
      "Run word 4 of all 500 sequences through the encoder\n",
      "Run word 5 of all 500 sequences through the encoder\n",
      "Run word 6 of all 500 sequences through the encoder\n",
      "Run word 7 of all 500 sequences through the encoder\n",
      "Run word 8 of all 500 sequences through the encoder\n",
      "Run word 9 of all 500 sequences through the encoder\n",
      "Run word 10 of all 500 sequences through the encoder\n",
      "Run word 11 of all 500 sequences through the encoder\n",
      "Run word 12 of all 500 sequences through the encoder\n",
      "Run word 13 of all 500 sequences through the encoder\n",
      "Run word 14 of all 500 sequences through the encoder\n",
      "Run word 15 of all 500 sequences through the encoder\n",
      "Run word 16 of all 500 sequences through the encoder\n",
      "Run word 17 of all 500 sequences through the encoder\n",
      "Run word 18 of all 500 sequences through the encoder\n",
      "Run word 19 of all 500 sequences through the encoder\n",
      "Run word 20 of all 500 sequences through the encoder\n"
     ]
    }
   ],
   "source": [
    "# Initialize the encoder hidden state and cell state with zeros\n",
    "hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "\n",
    "# Iterate over the sequence words and run every word through the encoder\n",
    "for i in range(input_seqs.shape[1]):\n",
    "    # Run the i-th word of the input sequence through the encoder.\n",
    "    # As a result we will get the prediction (output), the hidden state and the cell state.\n",
    "    # The hidden state and cell state will be used as inputs in the next round\n",
    "    print(f\"Run word {i+1} of all {input_seqs.shape[0]} sequences through the encoder\")\n",
    "    output, (hn, cn) = encoder(input_seqs[:, i].unsqueeze(dim=1), (hn, cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbb3c2a2-1b0a-404a-9d8c-0ae7fbc8485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 1, 20]), torch.Size([1, 500, 20]), torch.Size([1, 500, 20]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29054ba-e5b3-405f-bc5b-149f8862da81",
   "metadata": {},
   "source": [
    "# The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eda91121-2c2d-4531-b7ee-d67096698123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run word 1 through decoder\n",
      "Run word 2 through decoder\n",
      "Run word 3 through decoder\n",
      "Run word 4 through decoder\n",
      "Run word 5 through decoder\n",
      "Run word 6 through decoder\n",
      "Run word 7 through decoder\n",
      "Run word 8 through decoder\n",
      "Run word 9 through decoder\n",
      "Run word 10 through decoder\n",
      "Run word 11 through decoder\n",
      "Run word 12 through decoder\n",
      "Run word 13 through decoder\n",
      "Run word 14 through decoder\n",
      "Run word 15 through decoder\n",
      "Run word 16 through decoder\n",
      "Run word 17 through decoder\n",
      "Run word 18 through decoder\n",
      "Run word 19 through decoder\n",
      "Run word 20 through decoder\n",
      "LOSS tensor(63.9882, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "\n",
    "# Iterate over words of target sequence and run words through the decoder.\n",
    "# This will produce a prediction for the next word in the sequence\n",
    "for i in range(0, target_seqs.size(1)):\n",
    "    print(f\"Run word {i+1} through decoder\")\n",
    "    output, (hn, cn) = decoder(target_seqs[:, 0].unsqueeze(dim=1), (hn, cn))\n",
    "    loss += criterion(output.squeeze(), target_seqs[:, i])\n",
    "\n",
    "print(\"LOSS\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a5f9ad9-7ae1-4b49-99b8-490eacfd5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS after epoch 0 tensor(45.7595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 100 tensor(31.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 200 tensor(16.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 300 tensor(5.9200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 400 tensor(2.6844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 500 tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 600 tensor(1.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 700 tensor(0.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 800 tensor(0.5999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 900 tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1000 tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1100 tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1200 tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1300 tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1400 tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1500 tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1600 tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1700 tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1800 tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "LOSS after epoch 1900 tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    features, target_seqs = g.generate_synthetic_training_data(500, max_length=20, device=device)\n",
    "    features = features.to(device)\n",
    "    target_seqs = target_seqs.to(device)\n",
    "    input_seqs = torch.Tensor(features[:, :, 0]).to(torch.int64)\n",
    "    coordinates = torch.Tensor(features[:, :, 1:])\n",
    "\n",
    "    # Initialize the encoder hidden state and cell state with zeros\n",
    "    hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "    cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "\n",
    "    # Iterate over the sequence words and run every word through the encoder\n",
    "    for i in range(input_seqs.shape[1]):\n",
    "        # Run the i-th word of the input sequence through the encoder.\n",
    "        # As a result we will get the prediction (output), the hidden state and the cell state.\n",
    "        # The hidden state and cell state will be used as inputs in the next round\n",
    "        output, (hn, cn) = encoder(input_seqs[:, i].unsqueeze(dim=1), (hn, cn))\n",
    "\n",
    "    # Set gradients of all model parameters to zero\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Iterate over words of target sequence and run words through the decoder.\n",
    "    # This will produce a prediction for the next word in the sequence\n",
    "    for i in range(0, target_seqs.size(1)):\n",
    "        # Run word i+1 through decoder\n",
    "        output, (hn, cn) = decoder(target_seqs[:, i].unsqueeze(dim=1), (hn, cn))\n",
    "        loss += criterion(output.squeeze(), target_seqs[:, i])\n",
    "\n",
    "    history.append(loss)\n",
    "    if not epoch % 100:\n",
    "        print(f\"LOSS after epoch {epoch}\", loss)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights of encoder and decoder\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3605-8f59-42ee-b260-5bb500518d00",
   "metadata": {},
   "source": [
    "#### Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb67bec2-ccfd-4492-bd1a-e51fad94fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "model_data = {\n",
    "    \"history\": history,\n",
    "    \"lr\": lr,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_size\": hidden_size\n",
    "}\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\"training_\" + date_time\n",
    "\n",
    "with open(\"training_\" + date_time+ '.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56c813-13d3-45a2-b9e1-47fed03bcf3c",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "We run our input sequences through the model and get output seuences. Then we decode the output sequences with the Vocabulary class and get our final latex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0fb8ff7-8d9a-4c28-8f95-264703cfe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqgen.vocabulary import *\n",
    "\n",
    "vocab_in = Vocabulary(vocab_filename=\"seqgen/vocab_in.txt\")\n",
    "vocab_out = Vocabulary(vocab_filename=\"seqgen/vocab_out.txt\")\n",
    "\n",
    "predictions = torch.zeros(target_seqs.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize the encoder hidden state and cell state with zeros\n",
    "    hn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "    cn = encoder.initHidden(input_seqs.shape[0], device=features.device)\n",
    "\n",
    "    # Iterate over the sequence words and run every word through the encoder\n",
    "    for i in range(input_seqs.shape[1]):\n",
    "        output, (hn, cn) = encoder(input_seqs[:, i].unsqueeze(dim=1), (hn, cn))\n",
    "\n",
    "    for i in range(0, target_seqs.size(1)):\n",
    "        output, (hn, cn) = decoder(target_seqs[:, i].unsqueeze(dim=1), (hn, cn))\n",
    "        predicted_char = torch.argmax(output, dim=2)\n",
    "        predictions[:, i] = torch.argmax(output, dim=2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2cf18d6-94da-42ce-8bad-86a9f2d16d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INPUT ['<start>', '7', '7', '9', '9', '8', 'op_divide', '9', '5', '3', '1', '1', '7', 'op_minus', 'op_minus', '6', '4', '7', 'op_minus', '<end>']\n",
      "MODEL OUTPUT ['<start>', '7', '7', '9', '9', '8', '/', '9', '5', '3', '1', '1', '7', '-', '-', '6', '4', '7', '-', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# Pick random sequence and run it through the model\n",
    "import random\n",
    "\n",
    "i = random.randint(0, predictions.size(0))\n",
    "print(\"MODEL INPUT\", vocab_in.decode_sequence(input_seqs[i].cpu().numpy()))\n",
    "print(\"MODEL OUTPUT\", vocab_out.decode_sequence(predictions[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3d55a-0863-4876-a0a1-00f8b16e0f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
